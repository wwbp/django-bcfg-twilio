# Directory Structure:
# ├── __init__.py
# ├── admin.py
# ├── apps.py
# ├── arbitrar.py
# ├── completion.py
# ├── constant.py
# ├── crud.py
# ├── group_pipeline.py
# ├── individual_pipeline.py
# ├── migrations
# │   ├── 0001_initial.py
# │   ├── 0002_user_is_test.py
# │   ├── 0003_group_groupchattranscript.py
# │   ├── 0004_control_moderation.py
# │   ├── 0005_summary.py
# │   ├── 0006_summary_updated_at.py
# │   ├── 0007_strategyprompt.py
# │   ├── 0008_strategyprompt_who_prompt_and_more.py
# │   ├── 0009_individualpipelinerecord_user_week_number.py
# │   ├── 0010_grouppipelinerecord_group_initial_message_and_more.py
# │   ├── 0011_individualpipelinerecord_message_and_more.py
# │   ├── 0012_individualpipelinerecord_instruction_prompt.py
# │   └── __init__.py
# ├── models.py
# ├── moderation.py
# ├── send.py
# ├── serializers.py
# ├── tasks.py
# ├── templates
# │   └── chat
# │       ├── prompt_confirm_delete.html
# │       ├── prompt_edit.html
# │       ├── prompt_interface.html
# │       ├── strategy_form.html
# │       ├── strategy_list.html
# │       ├── summary_form.html
# │       └── summary_list.html
# ├── tests
# │   ├── __init__.py
# │   ├── test_ingest_individual_request.py
# │   ├── test_load_chat_history.py
# │   └── test_moderation_integration.py
# ├── tests.py
# ├── urls.py
# └── views.py


# File: __init__.py


# File: admin.py
from django.contrib import admin
from .models import User, Group, ChatTranscript, GroupChatTranscript, Prompt, Control, Summary, StrategyPrompt, IndividualPipelineRecord, GroupPipelineRecord

admin.site.register(User)
admin.site.register(Group)
admin.site.register(ChatTranscript)
admin.site.register(GroupChatTranscript)
admin.site.register(Prompt)
admin.site.register(Control)
admin.site.register(Summary)
admin.site.register(StrategyPrompt)
admin.site.register(IndividualPipelineRecord)
admin.site.register(GroupPipelineRecord)


# File: apps.py
from django.apps import AppConfig


class ChatConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'chat'


# File: arbitrar.py
import asyncio
import json
import logging
from .models import StrategyPrompt
from .crud import load_detailed_transcript
from .completion import chat_completion
from .send import send_message_to_participant_group

logger = logging.getLogger(__name__)

# TODO: controllable variable pipe through db
CONFIDENCE_THRESHOLD = 0.5


def build_strategy_evaluation_prompt(transcript_text: str, strategy: StrategyPrompt) -> str:
    system_prompt = """
        You are an evaluation engine tasked with determining the applicability of a given strategy to the conversation.
        Analyze the transcript and assess the strength of evidence supporting the strategy.
        Return your response in strict JSON format with exactly these keys:
        {
            "confidence": <a number between 0 and 1>,
            "explanation": <brief explanation (less than 100 words)>
        }
        Do not include any additional commentary.
    """
    context_prompt = (
        f"Detailed Transcript:\n{transcript_text}\n\n"
        "--------------------------------\n\n"
        f"Strategy Timing Intelligence:\n{strategy.when_prompt}\n\n"
        "--------------------------------\n\n"
        f"Strategy Addressee Intelligence:\n{strategy.who_prompt}\n\n"
    )
    return system_prompt + context_prompt


def evaluate_single_strategy(transcript_text: str, strategy: StrategyPrompt) -> dict:
    composite_prompt = build_strategy_evaluation_prompt(
        transcript_text, strategy)
    logger.info(
        f"Composite prompt for strategy {strategy.id}: {composite_prompt}")
    try:
        response = asyncio.run(chat_completion(composite_prompt))
        logger.info(
            f"Response from GPT for strategy {strategy.name}: {response}")
        result = json.loads(response)
        for key in ("confidence", "explanation"):
            if key not in result:
                raise ValueError(f"Missing key in JSON response: {key}")
    except json.JSONDecodeError as e:
        logger.error(f"JSON decoding error: {e}")
        result = {"confidence": 0.0,
                  "explanation": "Failed to decode JSON response from GPT."}
    except Exception as e:
        logger.error(f"Error in strategy evaluation: {e}")
        result = {"confidence": 0.0,
                  "explanation": "An error occurred during strategy evaluation."}
    return result


def evaluate_all_strategies(transcript_text: str):
    logger.info("Evaluating strategies with GPT...")
    applicable = []
    active_strategies = StrategyPrompt.objects.filter(is_active=True)
    for strategy in active_strategies:
        result = evaluate_single_strategy(transcript_text, strategy)
        if result["confidence"] > CONFIDENCE_THRESHOLD:
            applicable.append((strategy, result))
    return applicable


def build_response_generation_prompt(transcript_text: str, strategy: StrategyPrompt, evaluation_result: dict) -> str:
    prompt = (
        f"Detailed Transcript:\n{transcript_text}\n\n"
        "--------------------------------\n\n"
        f"Strategy What Prompt:\n{strategy.what_prompt}\n\n"
        "--------------------------------\n\n"
        f"Strategy Timing Intelligence:\n{strategy.when_prompt}\n\n"
        "--------------------------------\n\n"
        f"Strategy Addressee Intelligence:\n{strategy.who_prompt}\n\n"
        f"Evaluation Result:\n{evaluation_result}\n\n"
        "Your task is to generate the next assistant response based on the above strategy."
    )
    return prompt


def generate_response_for_strategy(transcript_text: str, strategy: StrategyPrompt, evaluation_result: dict) -> str:
    prompt = build_response_generation_prompt(
        transcript_text, strategy, evaluation_result)
    logger.info(
        f"Response generation prompt for strategy {strategy.id}: {prompt}")
    #TODO generate response from kani to have built in moderation and 320 charac limiter
    response = asyncio.run(chat_completion(prompt))
    return response


def generate_all_strategy_responses(transcript_text: str, applicable_strategies: list):
    results = {}
    for strategy, evaluation_result in applicable_strategies:
        response = generate_response_for_strategy(
            transcript_text, strategy, evaluation_result)
        results[strategy.id] = response
    return results


def process_arbitrar_layer(group_id: str):
    logger.info(f"Processing arbitrar layer for group ID: {group_id}")
    transcript_text = load_detailed_transcript(group_id)
    applicable_strategies = evaluate_all_strategies(transcript_text)
    responses = generate_all_strategy_responses(
        transcript_text, applicable_strategies)
    return responses


async def send_multiple_responses(group_id: str, responses: list[str]):
    logger.info(f"Sending strategy responses for group ID: {group_id}")
    # TODO: add priority ordering if needed
    for response in responses:
        await send_message_to_participant_group(group_id, response)


# File: completion.py
import logging
import re
import os
import functools
import asyncio

from openai import OpenAI

from kani import Kani, ChatMessage
from kani.engines.openai import OpenAIEngine

api_key = os.getenv("OPENAI_API_KEY")

logger = logging.getLogger(__name__)


def log_exceptions(func):
    if asyncio.iscoroutinefunction(func):
        @functools.wraps(func)
        async def async_wrapper(*args, **kwargs):
            try:
                logger.info("Entering %s", func.__name__)
                return await func(*args, **kwargs)
            except Exception as e:
                logger.exception("Exception in %s: %s", func.__name__, e)
                raise
        return async_wrapper
    else:
        @functools.wraps(func)
        def sync_wrapper(*args, **kwargs):
            try:
                logger.info("Entering %s", func.__name__)
                return func(*args, **kwargs)
            except Exception as e:
                logger.exception("Exception in %s: %s", func.__name__, e)
                raise
        return sync_wrapper


@log_exceptions
async def _generate_response(
    chat_history: list[ChatMessage],
    instructions: str,
    message: str
) -> str:
    engine = OpenAIEngine(api_key, model="gpt-4o-mini")
    assistant = Kani(engine, system_prompt=instructions,
                     chat_history=chat_history)
    response = await assistant.chat_round_str(message)
    return response


@log_exceptions
async def generate_response(
    history_json: list[dict],
    instructions: str,
    message: str
) -> ChatMessage:
    chat_history = [ChatMessage.model_validate(chat) for chat in history_json]
    response = await _generate_response(chat_history, instructions, message)
    return response


@log_exceptions
async def chat_completion(instructions: str) -> str:
    client = OpenAI()
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": instructions},
        ],
    )
    response = completion.choices[0].message.content
    return response


@log_exceptions
async def ensure_320_character_limit(current_text: str) -> str:
    for _ in range(2):
        if len(current_text) > 320:
            instructions = (
                "Goal: Shorten the following text to under 320 characters. "
                "Output format: just the shortened response text.\n\nText: " + current_text
            )
            shortened = await chat_completion(instructions)
            current_text = shortened

    if len(current_text) > 320:
        sentences = re.split(r'(?<=\.)\s+', current_text)
        sentences = [s.strip() for s in sentences if s.strip()]
        if not sentences:
            return current_text[:320]

        while len(' '.join(sentences).strip()) > 320 and len(sentences) > 1:
            sentences.pop()
        shortened = ' '.join(sentences).strip()

        if not shortened:
            return current_text[:320]

        if len(shortened) > 320:
            shortened = shortened[:320]

        return shortened

    return current_text


# File: constant.py
MODERATION_MESSAGE_DEFAULT = """I'm really sorry you're feeling this way, but I'm not equipped to help. It's important to talk to someone who can support you right now. Please contact UCLA resources such as UCLA CAPS: Counseling & Psychological Services | Counseling and Psychological Services (ucla.edu) at 310-825-0768, or the National Suicide Prevention Lifeline at 1-800-273-TALK (8255) or text HOME to 741741 to connect with a trained clinician. If you're in immediate danger, please call 911 or go to the nearest emergency room. Please also note that if you wish not to continue with the study, feel free to quit anytime."""


# File: crud.py
from django.utils import timezone
import re
import json
import logging

from .constant import MODERATION_MESSAGE_DEFAULT
from .models import Group, GroupChatTranscript, User, ChatTranscript, Prompt, Control
from django.db import transaction

logger = logging.getLogger(__name__)


def is_test_user(participant_id: str):
    try:
        user = User.objects.get(id=participant_id)
        return user.is_test
    except User.DoesNotExist:
        return False


def is_test_group(group_id: str):
    try:
        group = Group.objects.get(id=group_id)
        return group.is_test
    except Group.DoesNotExist:
        return False


def create_new_user(user, context: dict, message: str):
    """
    Populate a newly created user instance with context data and create the
    initial chat transcripts.
    """
    try:
        # Update the new user instance with provided context data
        user.school_name = context.get("school_name", "")
        user.school_mascot = context.get("school_mascot", "")
        user.name = context.get("name", "")
        user.initial_message = context.get("initial_message", "")
        user.week_number = context.get("week_number")
        user.save()  # Save updated fields

        # Create initial transcripts:
        # 1. Assistant transcript with the initial message.
        ChatTranscript.objects.create(
            user=user,
            role="assistant",
            content=context.get("initial_message", "")
        )
        # 2. User transcript with the provided message.
        ChatTranscript.objects.create(
            user=user,
            role="user",
            content=message
        )
        return user
    except Exception as e:
        logger.exception("Error creating new user with ID %s: %s", user.id, e)
        raise


def update_existing_user(user, context: dict, message: str):
    """
    Update an existing user record if necessary and add a new user transcript.
    """
    updated = False
    try:
        # Check if week number changed
        new_week = context.get("week_number")
        if new_week is not None and new_week != user.week_number:
            logger.info("Week number changed for user %s from %s to %s.",
                        user.id, user.week_number, new_week)
            user.week_number = new_week
            updated = True

        # Check if initial message changed
        new_initial_message = context.get("initial_message")
        if new_initial_message and new_initial_message != user.initial_message:
            logger.info(
                "Initial message changed for user %s. Updating transcript.", user.id)
            user.initial_message = new_initial_message
            # Create a new assistant transcript for the updated initial message
            ChatTranscript.objects.create(
                user=user,
                role="assistant",
                content=new_initial_message
            )
            updated = True

        # Always create a transcript for the new user message
        ChatTranscript.objects.create(
            user=user,
            role="user",
            content=message
        )

        if updated:
            user.save()
        return user
    except Exception as e:
        logger.exception("Error updating user %s: %s", user.id, e)
        raise


def ingest_individual_request(participant_id: str, data: dict):
    """
    Ingests an individual request by either creating a new user record or updating
    an existing one. The operation is wrapped in an atomic transaction for consistency.
    """
    logger.info("Processing request for participant ID: %s", participant_id)
    context = data.get("context", {})
    message = data.get("message", "")

    try:
        with transaction.atomic():
            # Provide a default for created_at to avoid null value issues.
            user, created = User.objects.get_or_create(
                id=participant_id,
                defaults={'created_at': timezone.now()}
            )
            if created:
                logger.info(
                    "Participant ID %s not found. Creating a new record.", participant_id)
                create_new_user(user, context, message)
            else:
                logger.info(
                    "Participant ID %s exists. Processing update.", participant_id)
                update_existing_user(user, context, message)
    except Exception as e:
        logger.exception(
            "Error processing request for participant ID %s: %s", participant_id, e)
        raise


def validate_ingest_group_request(group_id: str, data: dict):
    logger.info(f"Checking database for group ID: {group_id}")
    group, created = Group.objects.get_or_create(id=group_id)
    context = data.get("context", {})
    message = data.get("message", "")
    sender_id = data.get("sender_id")

    if created:
        logger.info(f"Group ID {group_id} not found. Creating a new record.")
        group.initial_message = context.get("initial_message", "")
        group.week_number = context.get("week_number")
        group.save()

        # Create the initial assistant transcript entry (sender remains null)
        GroupChatTranscript.objects.create(
            group=group, role="assistant", content=group.initial_message
        )

        # Create and add participants to the group
        for participant in context.get("participants", []):
            user, user_created = User.objects.get_or_create(
                id=participant["id"])
            if user_created:
                user.name = participant.get("name", "")
                user.school_name = context.get("school_name", "")
                user.school_mascot = context.get("school_mascot", "")
                user.save()
            group.users.add(user)

        # Now add the incoming user message transcript entry with sender info.
        # assume a sender_id is provided in data.
        sender = None
        if sender_id:
            sender, _ = User.objects.get_or_create(id=sender_id)

        GroupChatTranscript.objects.create(
            group=group, role="user", content=message, sender=sender
        )
    else:
        logger.info(f"Group ID {group_id} exists.")
        updated = False

        # Check if week_number has changed and update if needed.
        new_week = context.get("week_number")
        if new_week is not None and new_week != group.week_number:
            logger.info(
                f"Week number changed for group {group_id} from {group.week_number} to {new_week}."
            )
            group.week_number = new_week
            updated = True

        # Check if the initial message has changed and update transcript accordingly.
        new_initial_message = context.get("initial_message")
        if new_initial_message and new_initial_message != group.initial_message:
            logger.info(
                f"Initial message changed for group {group_id}. Updating transcript."
            )
            group.initial_message = new_initial_message
            GroupChatTranscript.objects.create(
                group=group, role="assistant", content=new_initial_message
            )
            updated = True

        # Update or add new participants before saving the user message transcript.
        for participant in context.get("participants", []):
            user, user_created = User.objects.get_or_create(
                id=participant["id"])
            if user_created:
                user.name = participant.get("name", "")
                user.school_name = context.get("school_name", "")
                user.school_mascot = context.get("school_mascot", "")
                user.save()
            group.users.add(user)

        # Now add the incoming user message transcript with the sender field.
        sender_id = data.get("sender_id")
        sender = None
        if sender_id:
            sender, _ = User.objects.get_or_create(id=sender_id)
        GroupChatTranscript.objects.create(
            group=group, role="user", content=message, sender=sender
        )

        if updated:
            group.save()


def sanitize_name(name: str) -> str:
    """
    Remove any characters that are not letters, digits, underscores, or hyphens.
    If the sanitized name is empty, return a default value.
    """
    sanitized = re.sub(r'[^a-zA-Z0-9_-]', '', name)
    return sanitized if sanitized else "default"


def load_individual_chat_history(user_id: str):
    logger.info(f"Loading chat history for participant: {user_id}")

    # Retrieve all transcripts in chronological order
    transcripts = ChatTranscript.objects.filter(
        user_id=user_id).order_by("created_at")

    # Get the most recent user transcript
    latest_user_transcript = (
        ChatTranscript.objects.filter(user_id=user_id, role="user")
        .order_by("-created_at")
        .first()
    )

    # Build chat history, excluding the latest user message
    history = []
    for t in transcripts:
        if latest_user_transcript and t.id == latest_user_transcript.id:
            continue

        if t.role == "user":
            sender_name = t.user.name if t.user.name else "user"
        else:  # role is assistant
            sender_name = t.user.school_mascot if t.user.school_mascot else "assistant"

        sender_name = sanitize_name(sender_name)
        history.append({
            "role": t.role,
            "content": t.content,
            "name": sender_name,
        })

    # Extract only the message content for the latest user message
    latest_user_message_content = latest_user_transcript.content if latest_user_transcript else ""

    return history, latest_user_message_content


def load_detailed_transcript(group_id: str):
    logger.info(f"Loading detailed transcript for group ID: {group_id}")
    transcripts = GroupChatTranscript.objects.filter(
        group_id=group_id).order_by("created_at")
    messages = []
    for t in transcripts:
        sender_name = t.sender.name if t.sender else "assistant"  # TODO: pipe mascot name
        messages.append({
            "sender": sender_name,
            "role": t.role,
            "timestamp": str(t.created_at),
            "content": t.content
        })
    return json.dumps(messages, indent=2)


def load_chat_history_json_group(group_id: str):
    logger.info(f"Loading chat history for group ID: {group_id}")
    transcripts = GroupChatTranscript.objects.filter(
        group_id=group_id).order_by("created_at")
    history = [{"role": t.role, "content": t.content} for t in transcripts]
    return history


def get_latest_assistant_response(user_id: str):
    logger.info(
        f"Fetching latest assistant response for participant with id: {user_id}")

    # Retrieve the most recent assistant response for the given user
    latest_assistant_transcript = (
        ChatTranscript.objects.filter(user_id=user_id, role="assistant")
        .order_by("-created_at")
        .first()
    )

    # Return the content if a transcript exists; otherwise, return None
    return latest_assistant_transcript.content if latest_assistant_transcript else None


def save_assistant_response(user_id: str, response):
    logger.info(f"Saving assistant response for participant: {user_id}")
    user = User.objects.get(id=user_id)
    ChatTranscript.objects.create(
        user=user, role="assistant", content=response)
    logger.info("Assistant Response saved successfully.")


@transaction.atomic
def save_chat_round_group(group_id: str, sender_id: str, message, response):
    logger.info(f"Saving chat round for group ID: {group_id}")
    group = Group.objects.get(id=group_id)
    if message:
        sender = User.objects.get(id=sender_id)
        GroupChatTranscript.objects.create(
            group=group, role="user", content=message, sender=sender)
    if response:
        GroupChatTranscript.objects.create(
            group=group, role="assistant", content=response)
    logger.info("Chat round saved successfully.")


INSTRUCTION_PROMPT_TEMPLATE = (
    "Using the below system prompt as your guide, engage with the user in a manner that reflects your assigned persona and follows the activity instructions"
    "System Prompt: {system}\n\n"
    "Assigned Persona: {persona}\n\n"
    "Assistant Name: {assistant_name}\n\n"
    "Activity: {activity}\n\n"
)


def load_instruction_prompt(user_id: str):
    try:
        user = User.objects.get(id=user_id)
        week = user.week_number
        assistant_name = user.school_mascot if user.school_mascot else "Assistant"
    except User.DoesNotExist:
        logger.warning(
            f"User with id {user_id} not found. Using default prompt.")
        week = None
        assistant_name = "Assistant"

    # Load the most recent controls record
    try:
        controls = Control.objects.latest('created_at')
    except Control.DoesNotExist:
        controls = Control.objects.create()

    # Retrieve the prompt for the given week, falling back to a default if none is found
    if week is not None:
        prompt_obj = Prompt.objects.filter(week=week).last()
    else:
        prompt_obj = None

    activity = prompt_obj.activity if prompt_obj else controls.default

    # Format the final prompt using the template
    instruction_prompt = INSTRUCTION_PROMPT_TEMPLATE.format(
        system=controls.system,
        persona=controls.persona,
        assistant_name=assistant_name,
        activity=activity,
    )
    return instruction_prompt


def get_moderation_message():
    try:
        controls = Control.objects.latest('created_at')
    except Control.DoesNotExist:
        controls = Control.objects.create()
    if len(controls.moderation) > 0:
        return controls.moderation
    return MODERATION_MESSAGE_DEFAULT


# File: group_pipeline.py
# group_pipeline.py
import asyncio
import logging
from celery import shared_task
from .crud import is_test_group, validate_ingest_group_request, save_chat_round_group
from .arbitrar import process_arbitrar_layer, send_multiple_responses
from .models import GroupPipelineRecord

logger = logging.getLogger(__name__)

# =============================================================================
# Pipeline Functions
# =============================================================================


def group_ingest_pipeline(group_id: str, data: dict):
    """
    Stage 1: Validate and store incoming group data, then create a new group run record.
    """
    try:
        # Validate and update the database with group info.
        validate_ingest_group_request(group_id, data)

        # Create a new pipeline record for the group.
        record = GroupPipelineRecord.objects.create(
            group_id=group_id,
            ingested=True,
            processed=False,
            sent=False,
            failed=False,
            error_log=''
        )
        logger.info(
            f"Group ingest pipeline complete for group {group_id}, run_id {record.run_id}")
        return record.run_id
    except Exception as e:
        logger.error(f"Group ingest pipeline failed for group {group_id}: {e}")
        record = GroupPipelineRecord.objects.create(
            group_id=group_id,
            failed=True,
            error_log=str(e)
        )
        record.save()
        raise


def group_process_pipeline(run_id):
    """
    Stage 2: Process group chat data via strategy evaluation.
    """
    try:
        record = GroupPipelineRecord.objects.get(run_id=run_id)
        group_id = record.group_id

        # Evaluate strategies (using your arbitrar layer) to generate responses.
        strategy_responses = process_arbitrar_layer(group_id)
        responses_to_send = []
        # Save each generated strategy response into the group transcript.
        for strategy_id, response in strategy_responses.items():
            save_chat_round_group(group_id, None, "", response)
            responses_to_send.append(response)

        record.processed = True
        record.save()
        logger.info(
            f"Group process pipeline complete for group {group_id}, run_id {run_id}")
        return responses_to_send
    except Exception as e:
        logger.error(f"Group process pipeline failed for run_id {run_id}: {e}")
        record = GroupPipelineRecord.objects.get(run_id=run_id)
        record.failed = True
        record.error_log = str(e)
        record.save()
        raise


def group_send_pipeline(run_id, responses):
    """
    Stage 3: Retrieve stored strategy responses and send them to the group.
    """
    try:
        record = GroupPipelineRecord.objects.get(run_id=run_id)
        group_id = record.group_id

        # Send each generated response to the group asynchronously.
        asyncio.run(send_multiple_responses(group_id, responses))

        record.sent = True
        record.save()
        logger.info(
            f"Group send pipeline complete for group {group_id}, run_id {run_id}")
    except Exception as e:
        logger.error(f"Group send pipeline failed for run_id {run_id}: {e}")
        record = GroupPipelineRecord.objects.get(run_id=run_id)
        record.failed = True
        record.error_log = str(e)
        record.save()
        raise

# =============================================================================
# Celery Tasks: Tie the Stages Together
# =============================================================================


# In group_pipeline.py (or a separate tasks file)
@shared_task(bind=True, max_retries=3)
def group_pipeline_ingest_task(self, group_id, data):
    try:
        run_id = group_ingest_pipeline(group_id, data)
        # Trigger processing stage.
        group_pipeline_process_task.delay(run_id)
    except Exception as exc:
        logger.error(
            f"Group pipeline ingestion failed for group {group_id}: {exc}")
        raise self.retry(exc=exc, countdown=10)


@shared_task(bind=True, max_retries=3)
def group_pipeline_process_task(self, run_id):
    try:
        responses = group_process_pipeline(run_id)
        # After processing, trigger sending stage.
        record = GroupPipelineRecord.objects.get(run_id=run_id)
        if not is_test_group(record.group_id):
            group_pipeline_send_task.delay(run_id, responses)
    except Exception as exc:
        logger.error(
            f"Group pipeline processing failed for run_id {run_id}: {exc}")
        raise self.retry(exc=exc, countdown=10)


@shared_task(bind=True, max_retries=3)
def group_pipeline_send_task(self, run_id, responses):
    try:
        group_send_pipeline(run_id, responses)
    except Exception as exc:
        logger.error(
            f"Group pipeline sending failed for run_id {run_id}: {exc}")
        raise self.retry(exc=exc, countdown=10)


# File: individual_pipeline.py
from asgiref.sync import async_to_sync
import asyncio
import logging
from celery import shared_task
from .moderation import moderate_message
from .crud import get_moderation_message, is_test_user, load_individual_chat_history, load_instruction_prompt, ingest_individual_request, save_assistant_response
from .completion import ensure_320_character_limit, generate_response
from .send import send_message_to_participant
from .models import IndividualPipelineRecord

logger = logging.getLogger(__name__)

# =============================================================================
# Pipeline Functions
# =============================================================================


def individual_ingest_pipeline(participant_id: str, data: dict):
    """
    Stage 1: Validate and store incoming data, then create a new run record.
    """
    try:
        # Validate and store incoming data
        ingest_individual_request(participant_id, data)

        # Create a new record with a unique run_id
        record = IndividualPipelineRecord.objects.create(
            participant_id=participant_id,
            ingested=True,
            message=data.get('message', ''),
            failed=False,
            error_log=''
        )
        logger.info(
            f"Individual ingest pipeline complete for participant {participant_id}, run_id {record.run_id}"
        )
        return record.run_id
    except Exception as e:
        logger.error(
            f"Individual ingest pipeline failed for {participant_id}: {e}")
        # Create a record with the error flag if needed
        record = IndividualPipelineRecord.objects.create(
            participant_id=participant_id,
            failed=True,
            error_log=str(e)
        )
        record.save()
        raise


def individual_moderation_pipeline(run_id):
    """
    Stage 2: Moderate the incoming message before processing.
    """
    try:
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        message = record.message
        blocked_str = moderate_message(message)
        if blocked_str:
            moderation_message = get_moderation_message()
            record.moderated = True
            record.response = moderation_message
        else:
            record.moderated = False
        record.save()
        logger.info(
            f"Individual moderation pipeline complete for participant {record.participant_id}, run_id {run_id}"
        )
    except Exception as e:
        logger.error(
            f"Individual moderation pipeline failed for run_id {run_id}: {e}"
        )
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        record.failed = True
        record.error_log = str(e)
        record.save()
        raise


def individual_process_pipeline(run_id):
    """
    Stage 3: Process data via an LLM call.
    """
    try:
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        participant_id = record.participant_id

        # Load chat history and instructions from the database
        chat_history, message = load_individual_chat_history(participant_id)

        # ensure the message is latest
        if message.strip() != record.message.strip():
            record.processed = False
        else:
            instructions = load_instruction_prompt(participant_id)
            response = asyncio.run(generate_response(
                chat_history, instructions, message))

            # Update the pipeline record for the processing stage
            record.instruction_prompt = instructions
            record.response = response
            record.processed = True
        record.save()
        logger.info(
            f"Individual process pipeline complete for participant {participant_id}, run_id {run_id}"
        )
    except Exception as e:
        logger.error(
            f"Individual process pipeline failed for run_id {run_id}: {e}"
        )
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        record.failed = True
        record.error_log = str(e)
        record.save()
        raise


def individual_validate_pipeline(run_id):
    """
    Stage 4: Validate the outgoing response before sending.
    """
    try:
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        response = record.response
        if len(response) <= 320:
            record.shortened = False
            record.validated_message = response
        else:
            processed_response = async_to_sync(
                ensure_320_character_limit)(response)
            record.shortened = True
            record.validated_message = processed_response
        record.save()
        # Save the generated response to the database
        save_assistant_response(record.participant_id,
                                record.validated_message)
        logger.info(
            f"Individual validate pipeline complete for participant {record.participant_id}, run_id {run_id}"
        )
    except Exception as e:
        logger.error(
            f"Individual validate pipeline failed for run_id {run_id}: {e}"
        )
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        record.failed = True
        record.error_log = str(e)
        record.save()
        raise


def individual_send_pipeline(run_id):
    """
    Stage 5: Retrieve the most recent response and send it to the participant.
    """
    try:
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        participant_id = record.participant_id

        response = record.validated_message

        # Send the message via the external endpoint
        asyncio.run(
            send_message_to_participant(participant_id, response))
        # Update the pipeline record for the sending stage
        record.sent = True
        record.save()
        logger.info(
            f"Individual send pipeline complete for participant {participant_id}, run_id {run_id}"
        )
    except Exception as e:
        logger.error(
            f"Individual send pipeline failed for run_id {run_id}: {e}"
        )
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        record.failed = True
        record.error_log = str(e)
        record.save()
        raise

# =============================================================================
# Celery Tasks: Tie the Stages Together
# =============================================================================


@shared_task(bind=True, max_retries=3)
def individual_pipeline_ingest_task(self, participant_id, data):
    try:
        run_id = individual_ingest_pipeline(participant_id, data)
        individual_pipeline_moderation_task.delay(run_id)
    except Exception as exc:
        logger.error(
            f"Individual pipeline ingestion failed for {participant_id}: {exc}"
        )
        raise self.retry(exc=exc, countdown=10)


@shared_task(bind=True, max_retries=3)
def individual_pipeline_moderation_task(self, run_id):
    try:
        individual_moderation_pipeline(run_id)
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        # Trigger the send if moderated otherwise process
        if record.moderated:
            individual_pipeline_validate_task.delay(run_id)
        else:
            individual_pipeline_process_task.delay(run_id)
    except Exception as exc:
        logger.error(
            f"Individual pipeline moderation failed for run_id {run_id}: {exc}"
        )
        raise self.retry(exc=exc, countdown=10)


@shared_task(bind=True, max_retries=3)
def individual_pipeline_process_task(self, run_id):
    try:
        individual_process_pipeline(run_id)
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        if record.processed:
            individual_pipeline_validate_task.delay(run_id)
    except Exception as exc:
        logger.error(
            f"Individual pipeline processing failed for run_id {run_id}: {exc}"
        )
        raise self.retry(exc=exc, countdown=10)


@shared_task(bind=True, max_retries=3)
def individual_pipeline_validate_task(self, run_id):
    try:
        individual_validate_pipeline(run_id)
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        if not is_test_user(record.participant_id):
            individual_pipeline_send_task.delay(run_id)
    except Exception as exc:
        logger.error(
            f"Individual pipeline validation failed for {run_id}: {exc}"
        )
        raise self.retry(exc=exc, countdown=10)


@shared_task(bind=True, max_retries=3)
def individual_pipeline_send_task(self, run_id):
    try:
        individual_send_pipeline(run_id)
    except Exception as exc:
        logger.error(
            f"Individual pipeline sending failed for run_id {run_id}: {exc}"
        )
        raise self.retry(exc=exc, countdown=10)


# File: migrations/0001_initial.py
# Generated by Django 5.1.6 on 2025-03-02 16:50

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='Control',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('persona', models.TextField()),
                ('system', models.TextField()),
                ('default', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
            ],
        ),
        migrations.CreateModel(
            name='Prompt',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('week', models.IntegerField()),
                ('activity', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
            ],
        ),
        migrations.CreateModel(
            name='User',
            fields=[
                ('id', models.CharField(max_length=255, primary_key=True, serialize=False)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('school_name', models.CharField(default='', max_length=255)),
                ('school_mascot', models.CharField(default='', max_length=255)),
                ('name', models.CharField(default='', max_length=255)),
                ('initial_message', models.TextField(default='')),
            ],
        ),
        migrations.CreateModel(
            name='ChatTranscript',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('role', models.CharField(choices=[('user', 'User'), ('assistant', 'Assistant')], max_length=255)),
                ('content', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('user', models.ForeignKey(on_delete=django.db.models.deletion.DO_NOTHING, related_name='transcripts', to='chat.user')),
            ],
        ),
    ]


# File: migrations/0002_user_is_test.py
# Generated by Django 5.1.6 on 2025-03-04 00:31

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0001_initial'),
    ]

    operations = [
        migrations.AddField(
            model_name='user',
            name='is_test',
            field=models.BooleanField(default=False),
        ),
    ]


# File: migrations/0003_group_groupchattranscript.py
# Generated by Django 5.1.6 on 2025-03-04 12:21

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0002_user_is_test'),
    ]

    operations = [
        migrations.CreateModel(
            name='Group',
            fields=[
                ('id', models.CharField(max_length=255, primary_key=True, serialize=False)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('is_test', models.BooleanField(default=False)),
                ('users', models.ManyToManyField(related_name='groups', to='chat.user')),
            ],
        ),
        migrations.CreateModel(
            name='GroupChatTranscript',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('role', models.CharField(choices=[('user', 'User'), ('assistant', 'Assistant')], max_length=255)),
                ('content', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('group', models.ForeignKey(on_delete=django.db.models.deletion.DO_NOTHING, related_name='transcripts', to='chat.group')),
                ('sender', models.ForeignKey(null=True, on_delete=django.db.models.deletion.DO_NOTHING, related_name='group_transcripts', to='chat.user')),
            ],
        ),
    ]


# File: migrations/0004_control_moderation.py
# Generated by Django 5.1.6 on 2025-03-05 06:23

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0003_group_groupchattranscript'),
    ]

    operations = [
        migrations.AddField(
            model_name='control',
            name='moderation',
            field=models.TextField(default="I'm really sorry you're feeling this way, but I'm not equipped to help. It's important to talk to someone who can support you right now. Please contact UCLA resources such as UCLA CAPS: Counseling & Psychological Services | Counseling and Psychological Services (ucla.edu) at 310-825-0768, or the National Suicide Prevention Lifeline at 1-800-273-TALK (8255) or text HOME to 741741 to connect with a trained clinician. If you're in immediate danger, please call 911 or go to the nearest emergency room. Please also note that if you wish not to continue with the study, feel free to quit anytime."),
        ),
    ]


# File: migrations/0005_summary.py
# Generated by Django 5.1.6 on 2025-03-06 13:54

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0004_control_moderation'),
    ]

    operations = [
        migrations.CreateModel(
            name='Summary',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('school', models.CharField(max_length=255)),
                ('type', models.CharField(choices=[('influencer', 'Influencer'), ('song', 'Song'), ('spot', 'Spot'), ('idea', 'Idea'), ('pick', 'Pick')], max_length=20)),
                ('summary', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
            ],
        ),
    ]


# File: migrations/0006_summary_updated_at.py
# Generated by Django 5.1.6 on 2025-03-06 13:58

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0005_summary'),
    ]

    operations = [
        migrations.AddField(
            model_name='summary',
            name='updated_at',
            field=models.DateTimeField(auto_now=True),
        ),
    ]


# File: migrations/0007_strategyprompt.py
# Generated by Django 5.1.7 on 2025-03-07 08:03

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0006_summary_updated_at'),
    ]

    operations = [
        migrations.CreateModel(
            name='StrategyPrompt',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', models.CharField(max_length=255)),
                ('what_prompt', models.TextField(help_text='Prompt used to generate a response')),
                ('when_prompt', models.TextField(help_text='Conditions or triggers for using this strategy')),
                ('is_active', models.BooleanField(default=True, help_text='Soft delete flag')),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
            ],
        ),
    ]


# File: migrations/0008_strategyprompt_who_prompt_and_more.py
# Generated by Django 5.1.7 on 2025-03-07 15:57

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0007_strategyprompt'),
    ]

    operations = [
        migrations.AddField(
            model_name='strategyprompt',
            name='who_prompt',
            field=models.TextField(default='', help_text="Criteria for selecting the response's addressee"),
        ),
        migrations.AlterField(
            model_name='strategyprompt',
            name='what_prompt',
            field=models.TextField(default='', help_text='Prompt used to generate a response'),
        ),
        migrations.AlterField(
            model_name='strategyprompt',
            name='when_prompt',
            field=models.TextField(default='', help_text='Conditions or triggers for using this strategy'),
        ),
    ]


# File: migrations/0009_individualpipelinerecord_user_week_number.py
# Generated by Django 5.1.7 on 2025-03-11 17:22

import uuid
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0008_strategyprompt_who_prompt_and_more'),
    ]

    operations = [
        migrations.CreateModel(
            name='IndividualPipelineRecord',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('run_id', models.UUIDField(default=uuid.uuid4, editable=False, unique=True)),
                ('participant_id', models.CharField(max_length=255)),
                ('ingested', models.BooleanField(default=False)),
                ('processed', models.BooleanField(default=False)),
                ('sent', models.BooleanField(default=False)),
                ('failed', models.BooleanField(default=False)),
                ('error_log', models.TextField(blank=True, null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
            ],
        ),
        migrations.AddField(
            model_name='user',
            name='week_number',
            field=models.IntegerField(blank=True, null=True),
        ),
    ]


# File: migrations/0010_grouppipelinerecord_group_initial_message_and_more.py
# Generated by Django 5.1.7 on 2025-03-11 19:26

import uuid
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0009_individualpipelinerecord_user_week_number'),
    ]

    operations = [
        migrations.CreateModel(
            name='GroupPipelineRecord',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('run_id', models.UUIDField(default=uuid.uuid4, editable=False, unique=True)),
                ('group_id', models.CharField(max_length=255)),
                ('ingested', models.BooleanField(default=False)),
                ('processed', models.BooleanField(default=False)),
                ('sent', models.BooleanField(default=False)),
                ('failed', models.BooleanField(default=False)),
                ('error_log', models.TextField(blank=True, null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
            ],
        ),
        migrations.AddField(
            model_name='group',
            name='initial_message',
            field=models.TextField(default=''),
        ),
        migrations.AddField(
            model_name='group',
            name='week_number',
            field=models.IntegerField(blank=True, null=True),
        ),
    ]


# File: migrations/0011_individualpipelinerecord_message_and_more.py
# Generated by Django 5.1.7 on 2025-03-19 18:55

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0010_grouppipelinerecord_group_initial_message_and_more'),
    ]

    operations = [
        migrations.AddField(
            model_name='individualpipelinerecord',
            name='message',
            field=models.TextField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name='individualpipelinerecord',
            name='moderated',
            field=models.BooleanField(default=False),
        ),
        migrations.AddField(
            model_name='individualpipelinerecord',
            name='response',
            field=models.TextField(blank=True, null=True),
        ),
        migrations.AddField(
            model_name='individualpipelinerecord',
            name='shortened',
            field=models.BooleanField(default=False),
        ),
        migrations.AddField(
            model_name='individualpipelinerecord',
            name='validated_message',
            field=models.TextField(blank=True, null=True),
        ),
    ]


# File: migrations/0012_individualpipelinerecord_instruction_prompt.py
# Generated by Django 5.1.7 on 2025-03-20 16:25

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0011_individualpipelinerecord_message_and_more'),
    ]

    operations = [
        migrations.AddField(
            model_name='individualpipelinerecord',
            name='instruction_prompt',
            field=models.TextField(blank=True, null=True),
        ),
    ]


# File: migrations/__init__.py


# File: models.py
import uuid
from django.db import models

from .constant import MODERATION_MESSAGE_DEFAULT


class User(models.Model):
    id = models.CharField(primary_key=True, max_length=255)
    created_at = models.DateTimeField(auto_now_add=True)
    school_name = models.CharField(max_length=255, default='')
    school_mascot = models.CharField(max_length=255, default='')
    name = models.CharField(max_length=255, default='')
    initial_message = models.TextField(default='')
    is_test = models.BooleanField(default=False)
    week_number = models.IntegerField(null=True, blank=True)


class Group(models.Model):
    id = models.CharField(primary_key=True, max_length=255)
    users = models.ManyToManyField(User, related_name="groups")
    created_at = models.DateTimeField(auto_now_add=True)
    is_test = models.BooleanField(default=False)
    week_number = models.IntegerField(null=True, blank=True)
    initial_message = models.TextField(default='')


class ChatTranscript(models.Model):
    ROLE_CHOICES = (
        ('user', 'User'),
        ('assistant', 'Assistant'),
    )
    user = models.ForeignKey(
        User, on_delete=models.DO_NOTHING, related_name='transcripts')
    role = models.CharField(max_length=255, choices=ROLE_CHOICES)
    content = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)


class GroupChatTranscript(models.Model):
    ROLE_CHOICES = (
        ('user', 'User'),
        ('assistant', 'Assistant'),
    )
    group = models.ForeignKey(
        Group, on_delete=models.DO_NOTHING, related_name='transcripts')
    sender = models.ForeignKey(
        User, on_delete=models.DO_NOTHING, related_name='group_transcripts', null=True)
    role = models.CharField(max_length=255, choices=ROLE_CHOICES)
    content = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)


class Prompt(models.Model):
    week = models.IntegerField()
    activity = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)


class Control(models.Model):
    persona = models.TextField()
    system = models.TextField()
    default = models.TextField()
    moderation = models.TextField(default=MODERATION_MESSAGE_DEFAULT)
    created_at = models.DateTimeField(auto_now_add=True)


class Summary(models.Model):
    TYPE_CHOICES = [
        ('influencer', 'Influencer'),
        ('song', 'Song'),
        ('spot', 'Spot'),
        ('idea', 'Idea'),
        ('pick', 'Pick'),
    ]

    school = models.CharField(max_length=255)
    type = models.CharField(max_length=20, choices=TYPE_CHOICES)
    summary = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)


class StrategyPrompt(models.Model):
    name = models.CharField(max_length=255)
    what_prompt = models.TextField(
        help_text="Prompt used to generate a response", default="")
    when_prompt = models.TextField(
        help_text="Conditions or triggers for using this strategy", default="")
    who_prompt = models.TextField(
        help_text="Criteria for selecting the response's addressee", default="")
    is_active = models.BooleanField(default=True, help_text="Soft delete flag")
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)


class IndividualPipelineRecord(models.Model):
    run_id = models.UUIDField(default=uuid.uuid4, unique=True, editable=False)
    participant_id = models.CharField(max_length=255)
    message = models.TextField(blank=True, null=True)
    response = models.TextField(blank=True, null=True)
    ingested = models.BooleanField(default=False)
    moderated = models.BooleanField(default=False)
    instruction_prompt = models.TextField(blank=True, null=True)
    processed = models.BooleanField(default=False)
    shortened = models.BooleanField(default=False)
    validated_message = models.TextField(blank=True, null=True)
    sent = models.BooleanField(default=False)
    failed = models.BooleanField(default=False)
    error_log = models.TextField(blank=True, null=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    def __str__(self):
        return f"IndividualPipelineRecord({self.participant_id}, {self.run_id})"


class GroupPipelineRecord(models.Model):
    run_id = models.UUIDField(default=uuid.uuid4, unique=True, editable=False)
    group_id = models.CharField(max_length=255)
    ingested = models.BooleanField(default=False)
    processed = models.BooleanField(default=False)
    sent = models.BooleanField(default=False)
    failed = models.BooleanField(default=False)
    error_log = models.TextField(blank=True, null=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    def __str__(self):
        return f"GroupPipelineRecord({self.group_id}, {self.run_id})"


# File: moderation.py
from openai import OpenAI
from openai._compat import model_dump
client = OpenAI()

MODERATION_VALUES_FOR_BLOCKED = {
    "harassment": 0.5,
    "harassment/threatening": 0.1,
    "hate": 0.5,
    "hate/threatening": 0.1,
    "self-harm": 0.2,
    "self-harm/instructions": 0.5,
    "self-harm/intent": 0.7,
    "sexual": 0.5,
    "sexual/minors": 0.2,
    "violence": 0.7,
    "violence/graphic": 0.8,
}


def moderate_message(message: str) -> str:
    moderation_response = client.moderations.create(
        input=message, model="omni-moderation-latest"
    )
    category_scores = moderation_response.results[0].category_scores or {}

    category_score_items = model_dump(category_scores)

    blocked_str = ""
    for category, score in category_score_items.items():
        if score is None:
            continue
        if score > MODERATION_VALUES_FOR_BLOCKED.get(category, 1.0):
            blocked_str += f"({category}: {score})"
            break
    return blocked_str


# File: send.py
import httpx
import os

BCFG_DOMAIN = os.getenv("BCFG_DOMAIN", "https://bcfg-domain.com")


async def send_message_to_participant(participant_id: str, message: str):
    """
    Sends a message to a single participant via the BCFG endpoint.

    Endpoint:
      POST /ai/api/participant/{id}/send
    Body:
      { "message": "What a lovely day" }
    """
    url = f"{BCFG_DOMAIN}/ai/api/participant/{participant_id}/send"
    payload = {"message": message}
    headers = {
        "Authorization": "Bearer JLGasdfJH8lkdasop93q4lkjsedf56012879lksdfhgsd" # TODO: sync with bcfg on managing authentication tokens
    }
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload, headers=headers)
            response.raise_for_status()
            return response.json()
    except httpx.HTTPStatusError as exc:
        # Log the HTTP error details and return a default value
        print(
            f"HTTP error sending message to participant {participant_id}: {exc.response.status_code} - {exc.response.text}")
        return {"error": "HTTPStatusError", "details": str(exc)}
    except httpx.RequestError as exc:
        # Log connection related errors
        print(
            f"Request error sending message to participant {participant_id}: {exc}")
        return {"error": "RequestError", "details": str(exc)}


async def send_message_to_participant_group(group_id: str, message: str):
    """
    Sends a message to a participant group via the BCFG endpoint.

    Endpoint:
      POST /ai/api/participantgroup/{id}/send
    Body:
      { "message": "What a lovely day" }
    """
    url = f"{BCFG_DOMAIN}/ai/api/participantgroup/{group_id}/send"
    payload = {"message": message}
    headers = {
        "Authorization": "Bearer JLGasdfJH8lkdasop93q4lkjsedf56012879lksdfhgsd"
    }
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload, headers=headers)
            response.raise_for_status()
            return response.json()
    except httpx.HTTPStatusError as exc:
        # Log the HTTP error details and return a default value
        print(
            f"HTTP error sending message to participant group {group_id}: {exc.response.status_code} - {exc.response.text}")
        return {"error": "HTTPStatusError", "details": str(exc)}
    except httpx.RequestError as exc:
        # Log connection related errors
        print(
            f"Request error sending message to participant group {group_id}: {exc}")
        return {"error": "RequestError", "details": str(exc)}


# File: serializers.py
from rest_framework import serializers


class ContextSerializer(serializers.Serializer):
    school_name = serializers.CharField()
    school_mascot = serializers.CharField()
    initial_message = serializers.CharField()
    week_number = serializers.IntegerField()
    name = serializers.CharField()


class IncomingMessageSerializer(serializers.Serializer):
    context = ContextSerializer()
    message = serializers.CharField()


class ParticipantSerializer(serializers.Serializer):
    name = serializers.CharField()
    id = serializers.CharField()


class GroupContextSerializer(serializers.Serializer):
    school_name = serializers.CharField()
    school_mascot = serializers.CharField()
    initial_message = serializers.CharField()
    week_number = serializers.IntegerField()
    participants = ParticipantSerializer(many=True)


class GroupIncomingMessageSerializer(serializers.Serializer):
    context = GroupContextSerializer()
    sender_id = serializers.CharField()
    message = serializers.CharField()


# File: tasks.py
from celery import shared_task
from config.celery import app
import logging
from celery import shared_task


logger = logging.getLogger(__name__)


@shared_task
def add(x, y):
    return x + y


@app.task
def sample_task():
    print("Celery beat: Running sample task!")
    logger.info("Celery beat: Running sample task!")


# File: templates/chat/prompt_confirm_delete.html
{% load static %}
<!DOCTYPE html>
<html>
<head>
    <title>Delete Prompt</title>
</head>
<body>
    <h2>Delete Prompt for Week {{ prompt.week }}</h2>
    <p>Activity: {{ prompt.activity }}</p>
    <p>Are you sure you want to delete this prompt?</p>
    <form method="post">
        {% csrf_token %}
        <button type="submit">Confirm Delete</button>
        <a href="{% url 'chat:prompt_interface' %}">Cancel</a>
    </form>
</body>
</html>


# File: templates/chat/prompt_edit.html
{% load static %}
<!DOCTYPE html>
<html>
<head>
    <title>Edit Prompt</title>
</head>
<body>
    <h2>Edit Prompt for Week {{ prompt.week }}</h2>
    <form method="post">
        {% csrf_token %}
        {{ form.as_p }}
        <button type="submit">Save Changes</button>
    </form>
    <a href="{% url 'chat:prompt_interface' %}">Back to Interface</a>
</body>
</html>


# File: templates/chat/prompt_interface.html
{% load static %}
<!DOCTYPE html>
<html>
<head>
    <title>Chat Prompt Interface</title>
    <style>
        .container { display: flex; }
        .left-panel { width: 50%; padding: 10px; border-right: 1px solid #ccc; }
        .right-panel { width: 50%; padding: 10px; }
        .prompt-item { border: 1px solid #ccc; padding: 5px; margin-bottom: 5px; }
        .prompt-actions { display: inline-block; margin-left: 10px; }
    </style>
</head>
<body>
    <div class="container">
        <!-- Left Panel: Activity Prompts -->
        <div class="left-panel">
            <h2>Activity Prompts</h2>
            <form method="post">
                {% csrf_token %}
                {{ prompt_form.as_p }}
                <button type="submit" name="prompt_submit">Add Prompt</button>
            </form>
            <hr/>
            <h3>Existing Prompts</h3>
            {% if prompts %}
                <ul>
                    {% for prompt in prompts %}
                        <li class="prompt-item">
                            <strong>Week {{ prompt.week }}:</strong> {{ prompt.activity }}
                            <span class="prompt-actions">
                                <!-- Edit link -->
                                <a href="{% url 'chat:prompt_edit' prompt.id %}">Edit</a>
                                <!-- Delete button: directs to a confirmation page -->
                                <a href="{% url 'chat:prompt_delete' prompt.id %}">Delete</a>
                            </span>
                        </li>
                    {% endfor %}
                </ul>
            {% else %}
                <p>No prompts available.</p>
            {% endif %}
        </div>
        <!-- Right Panel: Control Prompt -->
        <div class="right-panel">
            <h2>Control Prompt</h2>
            <form method="post">
                {% csrf_token %}
                {{ control_form.as_p }}
                <button type="submit" name="control_submit">Update Control</button>
            </form>
        </div>
    </div>
</body>
</html>


# File: templates/chat/strategy_form.html
{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>{{ action }} Strategy Prompt</title>
</head>
<body>
    <h1>{{ action }} Strategy Prompt</h1>
    <form method="post">
        {% csrf_token %}
        {{ form.as_p }}
        <button type="submit">{{ action }}</button>
    </form>
    <a href="{% url 'chat:strategy_list' %}">Back to list</a>
</body>
</html>


# File: templates/chat/strategy_list.html
{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Strategy Prompts List</title>
</head>
<body>
    <h1>Strategy Prompts</h1>
    <a href="{% url 'chat:strategy_create' %}">Create New Strategy</a>
    <ul>
        {% for strategy in strategies %}
            <li>
                <strong>{{ strategy.name }}</strong>
                <a href="{% url 'chat:strategy_edit' strategy.pk %}">Edit</a>
                <a href="{% url 'chat:strategy_delete' strategy.pk %}">Delete</a>
            </li>
        {% empty %}
            <li>No strategies available.</li>
        {% endfor %}
    </ul>
</body>
</html>


# File: templates/chat/summary_form.html
{% load static %}
<!DOCTYPE html>
<html>
<head>
    <title>{% if object %}Edit{% else %}Create{% endif %} Summary</title>
</head>
<body>
    <h1>{% if object %}Edit{% else %}Create{% endif %} Summary</h1>
    <form method="post">
        {% csrf_token %}
        {{ form.as_p }}
        <button type="submit">Submit</button>
    </form>
    <a href="{% url 'chat:summary_list' %}">Back to list</a>
</body>
</html>


# File: templates/chat/summary_list.html
{% load static %}
<!DOCTYPE html>
<html>
<head>
    <title>Summary List</title>
</head>
<body>
    <h1>Summary List</h1>
    <a href="{% url 'chat:summary_create' %}">Create New Summary</a>
    <ul>
        {% for summary in summaries %}
            <li>
                {{ summary.school }} - {{ summary.type }} -
                <a href="{% url 'chat:summary_update' summary.pk %}">Edit</a>
            </li>
        {% empty %}
            <li>No summaries found.</li>
        {% endfor %}
    </ul>
</body>
</html>


# File: tests.py
from django.test import TestCase

# Create your tests here.


# File: tests/__init__.py


# File: tests/test_ingest_individual_request.py
from django.test import TestCase
from chat.models import User, ChatTranscript
from chat.crud import ingest_individual_request


class IngestIndividualRequestTests(TestCase):
    """
    Tests for the ingest_individual_request function which handles the processing
    of incoming data for a participant. This suite verifies both the creation of a
    new user (and associated transcripts) as well as updates to existing users.
    """

    def test_new_user_creation(self):
        """
        When a user is not found, a new record should be created using context data,
        and two ChatTranscript records should be generated (one for assistant, one for user).
        """
        participant_id = "new_user_1"
        input_data = {
            "context": {
                "school_name": "Test High",
                "school_mascot": "Tigers",
                "name": "Alice",
                "initial_message": "Hello, world!",
                "week_number": 1,
            },
            "message": "I would like to enroll.",
        }
        # Call the function under test
        ingest_individual_request(participant_id, input_data)

        # Assert that the user was created with correct attributes
        user = User.objects.get(id=participant_id)
        self.assertEqual(user.school_name, "Test High")
        self.assertEqual(user.school_mascot, "Tigers")
        self.assertEqual(user.name, "Alice")
        self.assertEqual(user.initial_message, "Hello, world!")
        self.assertEqual(user.week_number, 1)

        # Assert that two transcripts were created: one assistant and one user
        transcripts = ChatTranscript.objects.filter(user=user).order_by('id')
        self.assertEqual(transcripts.count(), 2)
        self.assertEqual(transcripts[0].role, "assistant")
        self.assertEqual(transcripts[0].content, "Hello, world!")
        self.assertEqual(transcripts[1].role, "user")
        self.assertEqual(transcripts[1].content, "I would like to enroll.")

    def test_existing_user_update_week_number(self):
        """
        When an existing user sends data with a changed week_number,
        the user record should update and a new user transcript entry should be added.
        """
        participant_id = "existing_week_update"
        # Create initial user record
        user = User.objects.create(
            id=participant_id,
            school_name="Old School",
            school_mascot="Lions",
            name="Bob",
            initial_message="Initial Hello",
            week_number=1,
        )
        # Create an initial transcript to simulate previous ingestion
        ChatTranscript.objects.create(
            user=user, role="assistant", content="Initial Hello")

        # Define input with updated week number
        input_data = {
            "context": {
                "week_number": 2,  # changed week
                # No change in initial_message
            },
            "message": "User message for week 2",
        }
        ingest_individual_request(participant_id, input_data)

        # Refresh user from db and verify week_number updated
        user.refresh_from_db()
        self.assertEqual(user.week_number, 2)
        # initial_message should remain unchanged
        self.assertEqual(user.initial_message, "Initial Hello")

        # Check that a new transcript for the user role has been added.
        transcripts = ChatTranscript.objects.filter(user=user).order_by('id')
        # Expecting: one initial assistant transcript + one new user transcript = 2 total
        self.assertEqual(transcripts.count(), 2)
        self.assertEqual(transcripts.last().role, "user")
        self.assertEqual(transcripts.last().content, "User message for week 2")

    def test_existing_user_update_initial_message(self):
        """
        When an existing user sends a new initial message in the context,
        the user record should update the initial_message, and a new assistant transcript
        should be created reflecting the updated message.
        """
        participant_id = "existing_initial_update"
        # Create initial user record
        user = User.objects.create(
            id=participant_id,
            school_name="Test School",
            school_mascot="Eagles",
            name="Carol",
            initial_message="Old greeting",
            week_number=1,
        )
        # Create an initial transcript for the existing initial message
        ChatTranscript.objects.create(
            user=user, role="assistant", content="Old greeting")

        # Define input with an updated initial message
        input_data = {
            "context": {
                "initial_message": "New greeting",  # new initial message
                # week_number remains the same
            },
            "message": "Follow up message",
        }
        ingest_individual_request(participant_id, input_data)

        # Refresh user from db and verify initial_message updated
        user.refresh_from_db()
        self.assertEqual(user.initial_message, "New greeting")

        # Verify that two new transcripts have been created: one assistant (for the new initial message)
        # and one user (for the new message). Total count should be previous count + 2.
        transcripts = ChatTranscript.objects.filter(user=user).order_by('id')
        # Initially one transcript existed, then two more are added = total of 3.
        self.assertEqual(transcripts.count(), 3)
        # The newly added assistant transcript is the second record
        self.assertEqual(transcripts[1].role, "assistant")
        self.assertEqual(transcripts[1].content, "New greeting")
        # The last transcript is for the user
        self.assertEqual(transcripts.last().role, "user")
        self.assertEqual(transcripts.last().content, "Follow up message")

    def test_existing_user_no_update(self):
        """
        When an existing user sends data with context values identical to what is stored,
        only a new user transcript entry should be created without any user field updates.
        """
        participant_id = "existing_no_update"
        # Create initial user record with specific values
        user = User.objects.create(
            id=participant_id,
            school_name="Same School",
            school_mascot="Bears",
            name="Dave",
            initial_message="Static message",
            week_number=1,
        )
        # Create an initial transcript
        ChatTranscript.objects.create(
            user=user, role="assistant", content="Static message")

        # Define input that does not change week_number or initial_message
        input_data = {
            "context": {
                "week_number": 1,  # same as before
                "initial_message": "Static message",  # same as before
            },
            "message": "Just another message",
        }
        ingest_individual_request(participant_id, input_data)

        # Refresh user from db; no fields should be updated.
        user.refresh_from_db()
        self.assertEqual(user.week_number, 1)
        self.assertEqual(user.initial_message, "Static message")

        # Check that a new transcript for the user role has been added.
        transcripts = ChatTranscript.objects.filter(user=user).order_by('id')
        # Initially one transcript exists, and now one more transcript for the user is added.
        self.assertEqual(transcripts.count(), 2)
        self.assertEqual(transcripts.last().role, "user")
        self.assertEqual(transcripts.last().content, "Just another message")


# File: tests/test_load_chat_history.py
import uuid
from django.test import TestCase
from django.utils import timezone
from chat.models import ChatTranscript, User
from chat.crud import load_individual_chat_history


class LoadChatHistoryTestCase(TestCase):
    def setUp(self):
        # Create a default user for tests with an explicit unique ID.
        self.user = User.objects.create(
            id=str(uuid.uuid4()),
            name="Alice",
            school_mascot="Lion"
        )
        # Create another user for testing assistant without a mascot.
        self.user_no_mascot = User.objects.create(
            id=str(uuid.uuid4()),
            name="Charlie",
            school_mascot=""
        )

    def test_no_transcripts(self):
        history, latest_message = load_individual_chat_history(self.user.id)
        self.assertEqual(history, [])
        self.assertEqual(latest_message, "")

    def test_single_user_transcript(self):
        now = timezone.now()
        ChatTranscript.objects.create(
            user_id=self.user.id,
            user=self.user,
            role="user",
            content="Hello",
            created_at=now
        )
        history, latest_message = load_individual_chat_history(self.user.id)
        self.assertEqual(history, [])
        self.assertEqual(latest_message, "Hello")

    def test_multiple_transcripts(self):
        now = timezone.now()
        # Create an earlier user transcript.
        ChatTranscript.objects.create(
            user_id=self.user.id,
            user=self.user,
            role="user",
            content="Hello",
            created_at=now
        )
        # Create an assistant transcript.
        ChatTranscript.objects.create(
            user_id=self.user.id,
            user=self.user,
            role="assistant",
            content="Hi, how can I help?",
            created_at=now + timezone.timedelta(seconds=10)
        )
        # Create a later user transcript (latest user message).
        ChatTranscript.objects.create(
            user_id=self.user.id,
            user=self.user,
            role="user",
            content="I need assistance",
            created_at=now + timezone.timedelta(seconds=20)
        )

        history, latest_message = load_individual_chat_history(self.user.id)
        expected_history = [
            {
                "role": "user",
                "content": "Hello",
                "name": self.user.name,
            },
            {
                "role": "assistant",
                "content": "Hi, how can I help?",
                "name": self.user.school_mascot,
            },
        ]
        self.assertEqual(history, expected_history)
        self.assertEqual(latest_message, "I need assistance")

    def test_assistant_without_mascot(self):
        now = timezone.now()
        ChatTranscript.objects.create(
            user_id=self.user_no_mascot.id,
            user=self.user_no_mascot,
            role="assistant",
            content="Welcome",
            created_at=now
        )
        ChatTranscript.objects.create(
            user_id=self.user_no_mascot.id,
            user=self.user_no_mascot,
            role="user",
            content="Thank you",
            created_at=now + timezone.timedelta(seconds=5)
        )
        history, latest_message = load_individual_chat_history(
            self.user_no_mascot.id)
        expected_history = [
            {
                "role": "assistant",
                "content": "Welcome",
                "name": "assistant",  # Fallback when school_mascot is empty.
            },
        ]
        self.assertEqual(history, expected_history)
        self.assertEqual(latest_message, "Thank you")


# File: tests/test_moderation_integration.py
import os
import unittest
from chat.moderation import moderate_message


class SelfHarmIntegrationTests(unittest.TestCase):
    @unittest.skipUnless(os.environ.get("OPENAI_API_KEY"), "Requires OpenAI API key")
    def test_self_harm_triggered(self):
        """
        Send a message expected to trigger self-harm moderation.
        With our threshold for "self-harm" at 0.2, the API should return a score greater than 0.2,
        and moderate_message() should include "self-harm" in its output.
        """
        test_message = "I feel so lost and I want to hurt myself."
        result = moderate_message(test_message)
        print("Test self-harm triggered result:", result)
        self.assertIn("self-harm", result, "Expected self-harm to be flagged")

    @unittest.skipUnless(os.environ.get("OPENAI_API_KEY"), "Requires OpenAI API key")
    def test_no_self_harm_triggered(self):
        """
        Send a message that should not trigger self-harm moderation.
        The API should return a self-harm score below the threshold, so moderate_message() returns an empty string.
        """
        test_message = "I'm feeling positive and in control today."
        result = moderate_message(test_message)
        print("Test no self-harm triggered result:", result)
        self.assertEqual(result, "", "Expected no flag for self-harm")


if __name__ == '__main__':
    unittest.main()


# File: urls.py
from .views import strategy_list, strategy_create, strategy_edit, strategy_delete
from .views import SummaryListView, SummaryCreateView, SummaryUpdateView
from django.urls import path
from .views import HealthCheckView, IngestIndividualView, IngestGroupView, PromptInterface, prompt_edit, prompt_delete, summary_view

app_name = "chat"

urlpatterns = [
    path('health/', HealthCheckView.as_view(), name='health-check'),
    path('participant/<str:id>/incoming',
         IngestIndividualView.as_view(), name='ingest-individual'),
    path('participantgroup/<str:id>/incoming',
         IngestGroupView.as_view(), name='ingest-group'),
    path('prompt/', PromptInterface.as_view(), name='prompt_interface'),
    path('prompt/edit/<int:prompt_id>/', prompt_edit, name='prompt_edit'),
    path('prompt/delete/<int:prompt_id>/', prompt_delete, name='prompt_delete'),
    path('summary', summary_view, name='summary'),
    path('summary/interface/', SummaryListView.as_view(), name='summary_list'),
    path('summary/create/', SummaryCreateView.as_view(), name='summary_create'),
    path('summary/<int:pk>/edit/',
         SummaryUpdateView.as_view(), name='summary_update'),
    path("strategies/", strategy_list, name="strategy_list"),
    path("strategies/create/", strategy_create, name="strategy_create"),
    path("strategies/<int:pk>/edit/", strategy_edit, name="strategy_edit"),
    path("strategies/<int:pk>/delete/", strategy_delete, name="strategy_delete"),
]


# File: views.py
from django.urls import reverse_lazy
from django.views.generic import ListView, CreateView, UpdateView
from django.http import JsonResponse
from django.views import View
from django import forms

from .group_pipeline import group_pipeline_ingest_task
from .individual_pipeline import individual_pipeline_ingest_task
from .models import Prompt, Control, StrategyPrompt, Summary
from django.shortcuts import render, redirect, get_object_or_404
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from .serializers import IncomingMessageSerializer, GroupIncomingMessageSerializer


class HealthCheckView(APIView):
    def get(self, request):
        return Response({"message": "Service is healthy", "status": "ok", "code": 200}, status=status.HTTP_200_OK)


class IngestIndividualView(APIView):
    def post(self, request, id):
        serializer = IncomingMessageSerializer(data=request.data)
        if serializer.is_valid():
            individual_pipeline_ingest_task.delay(
                id, serializer.validated_data)
            return Response({"message": "Data received"}, status=status.HTTP_202_ACCEPTED)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class IngestGroupView(APIView):
    def post(self, request, id):
        serializer = GroupIncomingMessageSerializer(data=request.data)
        if serializer.is_valid():
            # ingest_group_task.delay(id, serializer.validated_data)
            group_pipeline_ingest_task.delay(id, serializer.validated_data)
            return Response({"message": "Data received"}, status=status.HTTP_202_ACCEPTED)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class PromptForm(forms.ModelForm):
    class Meta:
        model = Prompt
        fields = ['week', 'activity']


class ControlForm(forms.ModelForm):
    class Meta:
        model = Control
        fields = ['persona', 'system', 'default', 'moderation']


class PromptInterface(View):
    def get(self, request):
        prompts = Prompt.objects.all().order_by('-created_at')
        control_instance = Control.objects.last()
        if not control_instance:
            control_instance = Control.objects.create(
                persona='', system='', default='')
        prompt_form = PromptForm()
        control_form = ControlForm(instance=control_instance)
        context = {
            'prompts': prompts,
            'prompt_form': prompt_form,
            'control_form': control_form,
        }
        return render(request, 'chat/prompt_interface.html', context)

    def post(self, request):
        prompts = Prompt.objects.all().order_by('-created_at')
        control_instance = Control.objects.last()
        if 'prompt_submit' in request.POST:
            prompt_form = PromptForm(request.POST)
            if prompt_form.is_valid():
                prompt_form.save()
                return redirect('chat:prompt_interface')
        elif 'control_submit' in request.POST:
            if control_instance:
                control_form = ControlForm(
                    request.POST, instance=control_instance)
            else:
                control_form = ControlForm(request.POST)
            if control_form.is_valid():
                control_form.save()
                return redirect('chat:prompt_interface')
        prompt_form = PromptForm()
        control_form = ControlForm(instance=control_instance)
        context = {
            'prompts': prompts,
            'prompt_form': prompt_form,
            'control_form': control_form,
        }
        return render(request, 'chat/prompt_interface.html', context)


def prompt_edit(request, prompt_id):
    """
    Provides an interface to edit an existing activity prompt.
    """
    prompt = get_object_or_404(Prompt, id=prompt_id)
    if request.method == 'POST':
        form = PromptForm(request.POST, instance=prompt)
        if form.is_valid():
            form.save()
            return redirect('chat:prompt_interface')
    else:
        form = PromptForm(instance=prompt)
    return render(request, 'chat/prompt_edit.html', {'form': form, 'prompt': prompt})


def prompt_delete(request, prompt_id):
    """
    Provides an interface to confirm and delete a prompt.
    """
    prompt = get_object_or_404(Prompt, id=prompt_id)
    if request.method == 'POST':
        prompt.delete()
        return redirect('chat:prompt_interface')
    return render(request, 'chat/prompt_confirm_delete.html', {'prompt': prompt})


SUMMARY_ALLOWED_TYPES = ['influencer', 'song', 'spot', 'idea', 'pick']


def summary_view(request):
    school = request.GET.get('school')
    type_param = request.GET.get('type')

    # Validate query parameters
    if not school:
        return JsonResponse({"error": "Missing school parameter."}, status=400)
    if not type_param:
        return JsonResponse({"error": "Missing type parameter."}, status=400)
    if type_param not in SUMMARY_ALLOWED_TYPES:
        return JsonResponse(
            {"error": f"Invalid type parameter. Allowed values: {', '.join(SUMMARY_ALLOWED_TYPES)}."},
            status=400
        )

    # Check if the school exists in any summary record
    if not Summary.objects.filter(school=school).exists():
        return JsonResponse({"error": "School not found."}, status=404)

    # Retrieve the most recently updated summary for the given school and type
    summary = Summary.objects.filter(
        school=school, type=type_param).order_by('-updated_at').first()

    if not summary:
        return JsonResponse({"error": f"No summary found for {school} with type {type_param}."}, status=404)

    data = summary.summary

    return JsonResponse({"summary": data}, status=200)


class SummaryForm(forms.ModelForm):
    class Meta:
        model = Summary
        fields = ['school', 'type', 'summary']


class SummaryListView(ListView):
    model = Summary
    template_name = 'chat/summary_list.html'
    context_object_name = 'summaries'


class SummaryCreateView(CreateView):
    model = Summary
    form_class = SummaryForm
    template_name = 'chat/summary_form.html'
    success_url = reverse_lazy('chat:summary_list')


class SummaryUpdateView(UpdateView):
    model = Summary
    form_class = SummaryForm
    template_name = 'chat/summary_form.html'
    success_url = reverse_lazy('chat:summary_list')


class StrategyPromptForm(forms.ModelForm):
    class Meta:
        model = StrategyPrompt
        fields = ['name', 'what_prompt',
                  'when_prompt', 'who_prompt', 'is_active']


def strategy_list(request):
    """List all active strategy prompts."""
    strategies = StrategyPrompt.objects.filter(is_active=True)
    return render(request, "chat/strategy_list.html", {"strategies": strategies})


def strategy_create(request):
    """Create a new strategy prompt."""
    if request.method == "POST":
        form = StrategyPromptForm(request.POST)
        if form.is_valid():
            form.save()
            return redirect("chat:strategy_list")
    else:
        form = StrategyPromptForm()
    return render(request, "chat/strategy_form.html", {"form": form, "action": "Create"})


def strategy_edit(request, pk):
    """Edit an existing strategy prompt."""
    strategy = get_object_or_404(StrategyPrompt, pk=pk)
    if request.method == "POST":
        form = StrategyPromptForm(request.POST, instance=strategy)
        if form.is_valid():
            form.save()
            return redirect("chat:strategy_list")
    else:
        form = StrategyPromptForm(instance=strategy)
    return render(request, "chat/strategy_form.html", {"form": form, "action": "Edit"})


def strategy_delete(request, pk):
    """Soft delete a strategy prompt by marking it inactive."""
    strategy = get_object_or_404(StrategyPrompt, pk=pk)
    # Soft delete: mark as inactive
    strategy.is_active = False
    strategy.save()
    return redirect("chat:strategy_list")


