# Directory Structure:
# ├── __init__.py
# ├── admin.py
# ├── apps.py
# ├── arbitrar.py
# ├── completion.py
# ├── constant.py
# ├── crud.py
# ├── group_pipeline.py
# ├── individual_pipeline.py
# ├── migrations
# │   ├── 0001_initial.py
# │   ├── 0002_user_is_test.py
# │   ├── 0003_group_groupchattranscript.py
# │   ├── 0004_control_moderation.py
# │   ├── 0005_summary.py
# │   ├── 0006_summary_updated_at.py
# │   ├── 0007_strategyprompt.py
# │   ├── 0008_strategyprompt_who_prompt_and_more.py
# │   ├── 0009_individualpipelinerecord_user_week_number.py
# │   ├── 0010_grouppipelinerecord_group_initial_message_and_more.py
# │   └── __init__.py
# ├── models.py
# ├── moderation.py
# ├── send.py
# ├── serializers.py
# ├── tasks.py
# ├── templates
# │   └── chat
# │       ├── prompt_confirm_delete.html
# │       ├── prompt_edit.html
# │       ├── prompt_interface.html
# │       ├── strategy_form.html
# │       ├── strategy_list.html
# │       ├── summary_form.html
# │       └── summary_list.html
# ├── tests.py
# ├── urls.py
# └── views.py


# File: __init__.py


# File: admin.py
from django.contrib import admin

# Register your models here.


# File: apps.py
from django.apps import AppConfig


class ChatConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'chat'


# File: arbitrar.py
import asyncio
import json
from .models import StrategyPrompt
from .crud import load_detailed_transcript
from .completion import chat_completion
from .send import send_message_to_participant_group

import logging

logger = logging.getLogger(__name__)


def evaluate_strategy_confidence(transcript_text: str, strategy: StrategyPrompt) -> float:
    """
    For a given strategy, build a composite prompt that includes:
      - The detailed transcript
      - The strategy's 'when' condition (trigger)
      - The strategy's 'what' instruction prompt

    Then call GPT to generate a confidence score (0-1) for the strategy.
    """

    system_prompt = """
    You are an evaluation engine whose task is to determine whether a given strategy is applicable to the conversation based on the following inputs:

    **Your Task:**
    Analyze the conversation transcript and assess whether the Strategy Timing conditions are met. Be objective in your reasoning—only conclude that the strategy is applicable if the evidence is strong and the criteria are clearly satisfied. If there is any doubt or insufficient evidence, err on the side of caution.

    **Return Format:**
    Output your response in strict JSON format with exactly these keys:
    {
    "applicable": <true/false>, 
    "confidence": <a number between 0 and 1>, 
    "explanation": <brief explanation (less than 100 words)>
    }

    Do not include any additional commentary outside the JSON output. Evaluate based on the actual turns and active participation; do not rely solely on keywords. If unsure, return "applicable": false with a low confidence score.
    """

    # ** Context Dump **
    # 1. **Detailed Transcript:** A full transcript of a group conversation with multiple turns.
    # """ + f"2. **Strategy Timing Intelligence:** which relates to when the chatbot should respond. {strategy.when_prompt}" + """ + f"2.
    # 3. **Strategy Addressee Intelligence:** which relates to whom the chatbot should respond (e.g., a specific group, unspecified participants, or all participants) {strategy.when_prompt}" + """

    context_prompt = (
        f"1. **Detailed Transcript:** A full transcript of a group conversation with multiple turns.\n{transcript_text}\n\n"
        "--------------------------------\n\n"
        f"2. **Strategy Timing Intelligence:** which relates to when the chatbot should respond.\n {strategy.when_prompt}\n\n"
        "--------------------------------\n\n"
        f"3. **Strategy Addressee Intelligence:** which relates to whom the chatbot should respond (e.g., a specific group, unspecified participants, or all participants).\n {strategy.who_prompt}\n\n"
        "--------------------------------\n\n"
    )

    composite_prompt = context_prompt + system_prompt

    logging.info(
        f"Composite prompt for strategy {strategy.id}: {composite_prompt}")
    try:
        # Call the GPT completion function
        response = asyncio.run(chat_completion(composite_prompt))
        logging.info(
            f"Response from GPT for strategy {strategy.name}: {response}")

        # Attempt to parse the JSON output
        result = json.loads(response)

        # Check if required keys are in the JSON
        for key in ("applicable", "confidence", "explanation"):
            if key not in result:
                raise ValueError(f"Missing key in JSON response: {key}")

    except json.JSONDecodeError as e:
        logging.error(f"JSON decoding error: {e}")
        result = {
            "applicable": False,
            "confidence": 0.0,
            "explanation": "Failed to decode JSON response from GPT."
        }
    except Exception as e:
        logging.error(f"Error in strategy evaluation: {e}")
        result = {
            "applicable": False,
            "confidence": 0.0,
            "explanation": "An error occurred during strategy evaluation."
        }

    # Return tuple (is_applicable, detailed result)
    return result["applicable"], result


def evaluate_strategies_with_gpt(transcript_text: str):
    """
    Evaluate all active strategies by using GPT to generate a confidence score
    for each strategy against the given transcript.

    Returns:
      A sorted list of tuples (strategy, score) for strategies scoring above the threshold.
    """
    logging.info("Evaluating strategies with GPT...")
    applicable = []
    active_strategies = StrategyPrompt.objects.filter(is_active=True)
    for strategy in active_strategies:
        is_applicable, response = evaluate_strategy_confidence(
            transcript_text, strategy)
        if is_applicable:
            applicable.append((strategy, response))
    return applicable


def process_arbitrar_layer(group_id: str):
    """
    Process the arbitrar layer for a group conversation.

    Steps:
      1. Compile the detailed transcript.
      2. For each active strategy, use GPT to get a confidence score.
      3. For those with a score above the threshold, generate a response
         using the strategy's 'what' prompt and the latest message.

    Returns a dictionary mapping each strategy's name to its generated response and confidence score.
    """
    logging.info(f"Processing arbitrar layer for group ID: {group_id}")
    transcript_text = load_detailed_transcript(group_id)
    applicable_strategies = evaluate_strategies_with_gpt(transcript_text)

    results = {}
    for strategy, response in applicable_strategies:
        instructions = (
            f"Detailed Transcript:\n{transcript_text}\n\n"
            "--------------------------------\n\n"
            f"Strategy Intelligence, which relates to what the chatbot should respond.\n"
            f"Strategy What Prompt: {strategy.what_prompt}\n\n"
            "--------------------------------\n\n"
            "Strategy Timing Intelligence, which relates to what the chatbot should respond.\n"
            f"Strategy When Condition: {strategy.when_prompt}\n\n"
            "Strategy Addressee Intelligence, which relates to whom the chatbot should respond (e.g., a specific group, unspecified participants, or all participants).\n"
            f"Strategy Who Criteria: {strategy.who_prompt}\n\n"
            f"Results on if the strategy is applicable: {response}\n\n"
            "--------------------------------\n\n"
            "Your task is to generate next assistant response based on the strategy's intelligence instructions."
        )

        response = asyncio.run(chat_completion(instructions))
        results[strategy.id] = response
    return results


async def send_multiple_responses(group_id: str, responses: list[str]):
    """
    Asynchronously send each generated strategy response to the group.

    Each message is prefixed with the strategy name.
    """
    logging.info(f"Sending strategy responses for group ID: {group_id}")
    # TODO priority order and evaluation

    # for _, response in responses.items():
    #     await send_message_to_participant_group(group_id, response)

    for response in responses:
        await send_message_to_participant_group(group_id, response)


# File: completion.py
from asgiref.sync import sync_to_async
import os
from openai import OpenAI
from .crud import get_moderation_message
from .moderation import moderate_message
from kani import Kani, ChatMessage
from kani.engines.openai import OpenAIEngine


api_key = os.getenv(
    "OPENAI_API_KEY")


async def _generate_response(chat_history: list[ChatMessage], instructions: str, message: str) -> str:
    blocked_str = moderate_message(message)
    if blocked_str:
        moderation_message = await sync_to_async(get_moderation_message)()
        return moderation_message
    engine = OpenAIEngine(api_key, model="gpt-4o-mini")
    assistant = Kani(engine, system_prompt=instructions,
                     chat_history=chat_history)
    response = await assistant.chat_round_str(message)
    return response


async def generate_response(history_json: list[dict], instructions: str, message: str) -> ChatMessage:
    chat_history = [ChatMessage.model_validate(chat) for chat in history_json]
    response = await _generate_response(chat_history, instructions, message)
    return response


async def chat_completion(instructions: str):
    client = OpenAI()
    completion = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": instructions},
        ],
    )
    response = completion.choices[0].message.content
    return response


# File: constant.py
MODERATION_MESSAGE_DEFAULT = """I'm really sorry you're feeling this way, but I'm not equipped to help. It's important to talk to someone who can support you right now. Please contact UCLA resources such as UCLA CAPS: Counseling & Psychological Services | Counseling and Psychological Services (ucla.edu) at 310-825-0768, or the National Suicide Prevention Lifeline at 1-800-273-TALK (8255) or text HOME to 741741 to connect with a trained clinician. If you're in immediate danger, please call 911 or go to the nearest emergency room. Please also note that if you wish not to continue with the study, feel free to quit anytime."""


# File: crud.py
# chat/crud.py
import json
import logging

from .constant import MODERATION_MESSAGE_DEFAULT
from .models import Group, GroupChatTranscript, User, ChatTranscript, Prompt, Control
from django.db import transaction

logger = logging.getLogger(__name__)


def is_test_user(participant_id: str):
    try:
        user = User.objects.get(id=participant_id)
        return user.is_test
    except User.DoesNotExist:
        return False


def is_test_group(group_id: str):
    try:
        group = Group.objects.get(id=group_id)
        return group.is_test
    except Group.DoesNotExist:
        return False


def validate_ingest_individual_request(participant_id: str, data: dict):
    logger.info(
        f"Checking database for participant ID: {participant_id}")
    user, created = User.objects.get_or_create(id=participant_id)
    context = data.get("context", {})
    message = data.get("message", "")

    if created:
        logger.info(
            f"Participant ID {participant_id} not found. Creating a new record.")
        user.school_name = context.get("school_name", "")
        user.school_mascot = context.get("school_mascot", "")
        user.name = context.get("name", "")
        user.initial_message = context.get("initial_message", "")
        user.week_number = context.get("week_number")
        user.save()
        # Create an initial chat transcript entry with the initial message
        ChatTranscript.objects.create(
            user=user, role="assistant", content=context.get("initial_message", "")
        )
        ChatTranscript.objects.create(
            user=user, role="user", content=message
        )
    else:
        logger.info(f"Participant ID {participant_id} exists.")
        updated = False

        # Check if week number has changed and update if needed
        new_week = context.get("week_number")
        if new_week is not None and new_week != user.week_number:
            logger.info(
                f"Week number changed for user {participant_id} from {user.week_number} to {new_week}.")
            user.week_number = new_week
            updated = True

        # Check if initial message has changed
        new_initial_message = context.get("initial_message")
        if new_initial_message and new_initial_message != user.initial_message:
            logger.info(
                f"Initial message changed for user {participant_id}. Updating transcript.")
            user.initial_message = new_initial_message
            # Add the updated initial message to the transcript
            ChatTranscript.objects.create(
                user=user, role="assistant", content=new_initial_message
            )
            updated = True

        # after new initial message update user
        ChatTranscript.objects.create(
            user=user, role="user", content=message
        )

        if updated:
            user.save()


def validate_ingest_group_request(group_id: str, data: dict):
    logger.info(f"Checking database for group ID: {group_id}")
    group, created = Group.objects.get_or_create(id=group_id)
    context = data.get("context", {})
    message = data.get("message", "")
    sender_id = data.get("sender_id")

    if created:
        logger.info(f"Group ID {group_id} not found. Creating a new record.")
        group.initial_message = context.get("initial_message", "")
        group.week_number = context.get("week_number")
        group.save()

        # Create the initial assistant transcript entry (sender remains null)
        GroupChatTranscript.objects.create(
            group=group, role="assistant", content=group.initial_message
        )

        # Create and add participants to the group
        for participant in context.get("participants", []):
            user, user_created = User.objects.get_or_create(
                id=participant["id"])
            if user_created:
                user.name = participant.get("name", "")
                user.school_name = context.get("school_name", "")
                user.school_mascot = context.get("school_mascot", "")
                user.save()
            group.users.add(user)

        # Now add the incoming user message transcript entry with sender info.
        # assume a sender_id is provided in data.
        sender = None
        if sender_id:
            sender, _ = User.objects.get_or_create(id=sender_id)

        GroupChatTranscript.objects.create(
            group=group, role="user", content=message, sender=sender
        )
    else:
        logger.info(f"Group ID {group_id} exists.")
        updated = False

        # Check if week_number has changed and update if needed.
        new_week = context.get("week_number")
        if new_week is not None and new_week != group.week_number:
            logger.info(
                f"Week number changed for group {group_id} from {group.week_number} to {new_week}."
            )
            group.week_number = new_week
            updated = True

        # Check if the initial message has changed and update transcript accordingly.
        new_initial_message = context.get("initial_message")
        if new_initial_message and new_initial_message != group.initial_message:
            logger.info(
                f"Initial message changed for group {group_id}. Updating transcript."
            )
            group.initial_message = new_initial_message
            GroupChatTranscript.objects.create(
                group=group, role="assistant", content=new_initial_message
            )
            updated = True

        # Update or add new participants before saving the user message transcript.
        for participant in context.get("participants", []):
            user, user_created = User.objects.get_or_create(
                id=participant["id"])
            if user_created:
                user.name = participant.get("name", "")
                user.school_name = context.get("school_name", "")
                user.school_mascot = context.get("school_mascot", "")
                user.save()
            group.users.add(user)

        # Now add the incoming user message transcript with the sender field.
        sender_id = data.get("sender_id")
        sender = None
        if sender_id:
            sender, _ = User.objects.get_or_create(id=sender_id)
        GroupChatTranscript.objects.create(
            group=group, role="user", content=message, sender=sender
        )

        if updated:
            group.save()


def load_individual_chat_history(user_id: str):
    logger.info(f"Loading chat history for participant: {user_id}")

    # Retrieve all transcripts in chronological order
    transcripts = ChatTranscript.objects.filter(
        user_id=user_id).order_by("created_at")

    # Get the most recent user transcript
    latest_user_transcript = (
        ChatTranscript.objects.filter(user_id=user_id, role="user")
        .order_by("-created_at")
        .first()
    )

    # Build chat history, excluding the latest user message
    history = [
        {"role": t.role, "content": t.content}
        for t in transcripts
        if not (latest_user_transcript and t.id == latest_user_transcript.id)
    ]

    # Extract only the message content for the latest user message
    latest_user_message_content = latest_user_transcript.content if latest_user_transcript else ""

    return history, latest_user_message_content


def load_detailed_transcript(group_id: str):
    logger.info(f"Loading detailed transcript for group ID: {group_id}")
    transcripts = GroupChatTranscript.objects.filter(
        group_id=group_id).order_by("created_at")
    messages = []
    for t in transcripts:
        sender_name = t.sender.name if t.sender else "assistant"  # TODO: pipe mascot name
        messages.append({
            "sender": sender_name,
            "role": t.role,
            "timestamp": str(t.created_at),
            "content": t.content
        })
    return json.dumps(messages, indent=2)


def load_chat_history_json_group(group_id: str):
    logger.info(f"Loading chat history for group ID: {group_id}")
    transcripts = GroupChatTranscript.objects.filter(
        group_id=group_id).order_by("created_at")
    history = [{"role": t.role, "content": t.content} for t in transcripts]
    return history


def get_latest_assistant_response(user_id: str):
    logger.info(
        f"Fetching latest assistant response for participant with id: {user_id}")

    # Retrieve the most recent assistant response for the given user
    latest_assistant_transcript = (
        ChatTranscript.objects.filter(user_id=user_id, role="assistant")
        .order_by("-created_at")
        .first()
    )

    # Return the content if a transcript exists; otherwise, return None
    return latest_assistant_transcript.content if latest_assistant_transcript else None


def save_assistant_response(user_id: str, response):
    logger.info(f"Saving assistant response for participant: {user_id}")
    user = User.objects.get(id=user_id)
    ChatTranscript.objects.create(
        user=user, role="assistant", content=response)
    logger.info("Assistant Response saved successfully.")


@transaction.atomic
def save_chat_round_group(group_id: str, sender_id: str, message, response):
    logger.info(f"Saving chat round for group ID: {group_id}")
    group = Group.objects.get(id=group_id)
    if message:
        sender = User.objects.get(id=sender_id)
        GroupChatTranscript.objects.create(
            group=group, role="user", content=message, sender=sender)
    if response:
        GroupChatTranscript.objects.create(
            group=group, role="assistant", content=response)
    logger.info("Chat round saved successfully.")


INSTRUCTION_PROMPT_TEMPLATE = (
    "Using the below system prompt as your guide, engage with the user in a manner that reflects your assigned persona and follows the activity instructions"
    "System Prompt: {system}\n\n"
    "Assigned Persona: {persona}\n\n"
    "Activity: {activity}\n\n"
)


def load_instruction_prompt(user_id: str):
    try:
        user = User.objects.get(id=user_id)
        week = user.week_number
    except User.DoesNotExist:
        logger.warning(
            f"User with id {user_id} not found. Using default prompt.")
        week = None

    # Load the most recent controls record
    try:
        controls = Control.objects.latest('created_at')
    except Control.DoesNotExist:
        controls = Control.objects.create()

    # Retrieve the prompt for the given week, falling back to a default if none is found
    if week is not None:
        prompt_obj = Prompt.objects.filter(week=week).last()
    else:
        prompt_obj = None

    activity = prompt_obj.activity if prompt_obj else controls.default

    # Format the final prompt using the template
    instruction_prompt = INSTRUCTION_PROMPT_TEMPLATE.format(
        system=controls.system,
        persona=controls.persona,
        activity=activity,
    )
    return instruction_prompt


def get_moderation_message():
    try:
        controls = Control.objects.latest('created_at')
    except Control.DoesNotExist:
        controls = Control.objects.create()
    if len(controls.moderation) > 0:
        return controls.moderation
    return MODERATION_MESSAGE_DEFAULT


# File: group_pipeline.py
# group_pipeline.py
import asyncio
import logging
from celery import shared_task
from .crud import is_test_group, validate_ingest_group_request, save_chat_round_group
from .arbitrar import process_arbitrar_layer, send_multiple_responses
from .models import GroupPipelineRecord

logger = logging.getLogger(__name__)

# =============================================================================
# Pipeline Functions
# =============================================================================


def group_ingest_pipeline(group_id: str, data: dict):
    """
    Stage 1: Validate and store incoming group data, then create a new group run record.
    """
    try:
        # Validate and update the database with group info.
        validate_ingest_group_request(group_id, data)

        # Create a new pipeline record for the group.
        record = GroupPipelineRecord.objects.create(
            group_id=group_id,
            ingested=True,
            processed=False,
            sent=False,
            failed=False,
            error_log=''
        )
        logger.info(
            f"Group ingest pipeline complete for group {group_id}, run_id {record.run_id}")
        return record.run_id
    except Exception as e:
        logger.error(f"Group ingest pipeline failed for group {group_id}: {e}")
        record = GroupPipelineRecord.objects.create(
            group_id=group_id,
            failed=True,
            error_log=str(e)
        )
        record.save()
        raise


def group_process_pipeline(run_id):
    """
    Stage 2: Process group chat data via strategy evaluation.
    """
    try:
        record = GroupPipelineRecord.objects.get(run_id=run_id)
        group_id = record.group_id

        # Evaluate strategies (using your arbitrar layer) to generate responses.
        strategy_responses = process_arbitrar_layer(group_id)
        responses_to_send = []
        # Save each generated strategy response into the group transcript.
        for strategy_id, response in strategy_responses.items():
            save_chat_round_group(group_id, None, "", response)
            responses_to_send.append(response)

        record.processed = True
        record.save()
        logger.info(
            f"Group process pipeline complete for group {group_id}, run_id {run_id}")
        return responses_to_send
    except Exception as e:
        logger.error(f"Group process pipeline failed for run_id {run_id}: {e}")
        record = GroupPipelineRecord.objects.get(run_id=run_id)
        record.failed = True
        record.error_log = str(e)
        record.save()
        raise


def group_send_pipeline(run_id, responses):
    """
    Stage 3: Retrieve stored strategy responses and send them to the group.
    """
    try:
        record = GroupPipelineRecord.objects.get(run_id=run_id)
        group_id = record.group_id

        # Send each generated response to the group asynchronously.
        asyncio.run(send_multiple_responses(group_id, responses))

        record.sent = True
        record.save()
        logger.info(
            f"Group send pipeline complete for group {group_id}, run_id {run_id}")
    except Exception as e:
        logger.error(f"Group send pipeline failed for run_id {run_id}: {e}")
        record = GroupPipelineRecord.objects.get(run_id=run_id)
        record.failed = True
        record.error_log = str(e)
        record.save()
        raise

# =============================================================================
# Celery Tasks: Tie the Stages Together
# =============================================================================


# In group_pipeline.py (or a separate tasks file)
@shared_task(bind=True, max_retries=3)
def group_pipeline_ingest_task(self, group_id, data):
    try:
        run_id = group_ingest_pipeline(group_id, data)
        # Trigger processing stage.
        group_pipeline_process_task.delay(run_id)
    except Exception as exc:
        logger.error(
            f"Group pipeline ingestion failed for group {group_id}: {exc}")
        raise self.retry(exc=exc, countdown=10)


@shared_task(bind=True, max_retries=3)
def group_pipeline_process_task(self, run_id):
    try:
        responses = group_process_pipeline(run_id)
        # After processing, trigger sending stage.
        record = GroupPipelineRecord.objects.get(run_id=run_id)
        if not is_test_group(record.group_id):
            group_pipeline_send_task.delay(run_id, responses)
    except Exception as exc:
        logger.error(
            f"Group pipeline processing failed for run_id {run_id}: {exc}")
        raise self.retry(exc=exc, countdown=10)


@shared_task(bind=True, max_retries=3)
def group_pipeline_send_task(self, run_id, responses):
    try:
        group_send_pipeline(run_id, responses)
    except Exception as exc:
        logger.error(
            f"Group pipeline sending failed for run_id {run_id}: {exc}")
        raise self.retry(exc=exc, countdown=10)


# File: individual_pipeline.py
import asyncio
import logging
from celery import shared_task
from .crud import get_latest_assistant_response, is_test_user, load_individual_chat_history, load_instruction_prompt, save_assistant_response, validate_ingest_individual_request
from .completion import generate_response
from .send import send_message_to_participant
from .models import IndividualPipelineRecord

logger = logging.getLogger(__name__)

# =============================================================================
# Pipeline Functions
# =============================================================================


def individual_ingest_pipeline(participant_id: str, data: dict):
    """
    Stage 1: Validate and store incoming data, then create a new run record.
    """
    try:
        # Validate and store incoming data
        validate_ingest_individual_request(participant_id, data)

        # Create a new record with a unique run_id
        record = IndividualPipelineRecord.objects.create(
            participant_id=participant_id,
            ingested=True,
            failed=False,
            error_log=''
        )
        logger.info(
            f"Individual ingest pipeline complete for participant {participant_id}, run_id {record.run_id}"
        )
        return record.run_id
    except Exception as e:
        logger.error(
            f"Individual ingest pipeline failed for {participant_id}: {e}")
        # Create a record with the error flag if needed
        record = IndividualPipelineRecord.objects.create(
            participant_id=participant_id,
            failed=True,
            error_log=str(e)
        )
        record.save()
        raise


def individual_process_pipeline(run_id):
    """
    Stage 2: Process data via an LLM call.
    """
    try:
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        participant_id = record.participant_id

        # Load chat history and instructions from the database
        chat_history, message = load_individual_chat_history(participant_id)
        instructions = load_instruction_prompt(participant_id)

        # Generate a response using the LLM
        response = asyncio.run(generate_response(
            chat_history, instructions, message))

        # Save the generated response to the database
        save_assistant_response(participant_id, response)

        # Update the pipeline record for the processing stage
        record.processed = True
        record.save()
        logger.info(
            f"Individual process pipeline complete for participant {participant_id}, run_id {run_id}"
        )
    except Exception as e:
        logger.error(
            f"Individual process pipeline failed for run_id {run_id}: {e}"
        )
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        record.failed = True
        record.error_log = str(e)
        record.save()
        raise


def individual_send_pipeline(run_id):
    """
    Stage 3: Retrieve the most recent response and send it to the participant.
    """
    try:
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        participant_id = record.participant_id

        # Retrieve the most recent assistant response
        response = get_latest_assistant_response(participant_id)

        # Send the message via the external endpoint
        asyncio.run(
            send_message_to_participant(participant_id, response))
        # Update the pipeline record for the sending stage
        record.sent = True
        record.save()
        logger.info(
            f"Individual send pipeline complete for participant {participant_id}, run_id {run_id}"
        )
    except Exception as e:
        logger.error(
            f"Individual send pipeline failed for run_id {run_id}: {e}"
        )
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        record.failed = True
        record.error_log = str(e)
        record.save()
        raise

# =============================================================================
# Celery Tasks: Tie the Stages Together
# =============================================================================


@shared_task(bind=True, max_retries=3)
def individual_pipeline_ingest_task(self, participant_id, data):
    try:
        run_id = individual_ingest_pipeline(participant_id, data)
        # Trigger the next stage: processing
        individual_pipeline_process_task.delay(run_id)
    except Exception as exc:
        logger.error(
            f"Individual pipeline ingestion failed for {participant_id}: {exc}"
        )
        raise self.retry(exc=exc, countdown=10)


@shared_task(bind=True, max_retries=3)
def individual_pipeline_process_task(self, run_id):
    try:
        individual_process_pipeline(run_id)
        record = IndividualPipelineRecord.objects.get(run_id=run_id)
        # Use participant_id from the record to check test user status
        if not is_test_user(record.participant_id):
            individual_pipeline_send_task.delay(run_id)
    except Exception as exc:
        logger.error(
            f"Individual pipeline processing failed for run_id {run_id}: {exc}"
        )
        raise self.retry(exc=exc, countdown=10)


@shared_task(bind=True, max_retries=3)
def individual_pipeline_send_task(self, run_id):
    try:
        individual_send_pipeline(run_id)
    except Exception as exc:
        logger.error(
            f"Individual pipeline sending failed for run_id {run_id}: {exc}"
        )
        raise self.retry(exc=exc, countdown=10)


# File: migrations/0001_initial.py
# Generated by Django 5.1.6 on 2025-03-02 16:50

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='Control',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('persona', models.TextField()),
                ('system', models.TextField()),
                ('default', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
            ],
        ),
        migrations.CreateModel(
            name='Prompt',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('week', models.IntegerField()),
                ('activity', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
            ],
        ),
        migrations.CreateModel(
            name='User',
            fields=[
                ('id', models.CharField(max_length=255, primary_key=True, serialize=False)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('school_name', models.CharField(default='', max_length=255)),
                ('school_mascot', models.CharField(default='', max_length=255)),
                ('name', models.CharField(default='', max_length=255)),
                ('initial_message', models.TextField(default='')),
            ],
        ),
        migrations.CreateModel(
            name='ChatTranscript',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('role', models.CharField(choices=[('user', 'User'), ('assistant', 'Assistant')], max_length=255)),
                ('content', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('user', models.ForeignKey(on_delete=django.db.models.deletion.DO_NOTHING, related_name='transcripts', to='chat.user')),
            ],
        ),
    ]


# File: migrations/0002_user_is_test.py
# Generated by Django 5.1.6 on 2025-03-04 00:31

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0001_initial'),
    ]

    operations = [
        migrations.AddField(
            model_name='user',
            name='is_test',
            field=models.BooleanField(default=False),
        ),
    ]


# File: migrations/0003_group_groupchattranscript.py
# Generated by Django 5.1.6 on 2025-03-04 12:21

import django.db.models.deletion
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0002_user_is_test'),
    ]

    operations = [
        migrations.CreateModel(
            name='Group',
            fields=[
                ('id', models.CharField(max_length=255, primary_key=True, serialize=False)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('is_test', models.BooleanField(default=False)),
                ('users', models.ManyToManyField(related_name='groups', to='chat.user')),
            ],
        ),
        migrations.CreateModel(
            name='GroupChatTranscript',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('role', models.CharField(choices=[('user', 'User'), ('assistant', 'Assistant')], max_length=255)),
                ('content', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('group', models.ForeignKey(on_delete=django.db.models.deletion.DO_NOTHING, related_name='transcripts', to='chat.group')),
                ('sender', models.ForeignKey(null=True, on_delete=django.db.models.deletion.DO_NOTHING, related_name='group_transcripts', to='chat.user')),
            ],
        ),
    ]


# File: migrations/0004_control_moderation.py
# Generated by Django 5.1.6 on 2025-03-05 06:23

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0003_group_groupchattranscript'),
    ]

    operations = [
        migrations.AddField(
            model_name='control',
            name='moderation',
            field=models.TextField(default="I'm really sorry you're feeling this way, but I'm not equipped to help. It's important to talk to someone who can support you right now. Please contact UCLA resources such as UCLA CAPS: Counseling & Psychological Services | Counseling and Psychological Services (ucla.edu) at 310-825-0768, or the National Suicide Prevention Lifeline at 1-800-273-TALK (8255) or text HOME to 741741 to connect with a trained clinician. If you're in immediate danger, please call 911 or go to the nearest emergency room. Please also note that if you wish not to continue with the study, feel free to quit anytime."),
        ),
    ]


# File: migrations/0005_summary.py
# Generated by Django 5.1.6 on 2025-03-06 13:54

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0004_control_moderation'),
    ]

    operations = [
        migrations.CreateModel(
            name='Summary',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('school', models.CharField(max_length=255)),
                ('type', models.CharField(choices=[('influencer', 'Influencer'), ('song', 'Song'), ('spot', 'Spot'), ('idea', 'Idea'), ('pick', 'Pick')], max_length=20)),
                ('summary', models.TextField()),
                ('created_at', models.DateTimeField(auto_now_add=True)),
            ],
        ),
    ]


# File: migrations/0006_summary_updated_at.py
# Generated by Django 5.1.6 on 2025-03-06 13:58

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0005_summary'),
    ]

    operations = [
        migrations.AddField(
            model_name='summary',
            name='updated_at',
            field=models.DateTimeField(auto_now=True),
        ),
    ]


# File: migrations/0007_strategyprompt.py
# Generated by Django 5.1.7 on 2025-03-07 08:03

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0006_summary_updated_at'),
    ]

    operations = [
        migrations.CreateModel(
            name='StrategyPrompt',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', models.CharField(max_length=255)),
                ('what_prompt', models.TextField(help_text='Prompt used to generate a response')),
                ('when_prompt', models.TextField(help_text='Conditions or triggers for using this strategy')),
                ('is_active', models.BooleanField(default=True, help_text='Soft delete flag')),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
            ],
        ),
    ]


# File: migrations/0008_strategyprompt_who_prompt_and_more.py
# Generated by Django 5.1.7 on 2025-03-07 15:57

from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0007_strategyprompt'),
    ]

    operations = [
        migrations.AddField(
            model_name='strategyprompt',
            name='who_prompt',
            field=models.TextField(default='', help_text="Criteria for selecting the response's addressee"),
        ),
        migrations.AlterField(
            model_name='strategyprompt',
            name='what_prompt',
            field=models.TextField(default='', help_text='Prompt used to generate a response'),
        ),
        migrations.AlterField(
            model_name='strategyprompt',
            name='when_prompt',
            field=models.TextField(default='', help_text='Conditions or triggers for using this strategy'),
        ),
    ]


# File: migrations/0009_individualpipelinerecord_user_week_number.py
# Generated by Django 5.1.7 on 2025-03-11 17:22

import uuid
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0008_strategyprompt_who_prompt_and_more'),
    ]

    operations = [
        migrations.CreateModel(
            name='IndividualPipelineRecord',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('run_id', models.UUIDField(default=uuid.uuid4, editable=False, unique=True)),
                ('participant_id', models.CharField(max_length=255)),
                ('ingested', models.BooleanField(default=False)),
                ('processed', models.BooleanField(default=False)),
                ('sent', models.BooleanField(default=False)),
                ('failed', models.BooleanField(default=False)),
                ('error_log', models.TextField(blank=True, null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
            ],
        ),
        migrations.AddField(
            model_name='user',
            name='week_number',
            field=models.IntegerField(blank=True, null=True),
        ),
    ]


# File: migrations/0010_grouppipelinerecord_group_initial_message_and_more.py
# Generated by Django 5.1.7 on 2025-03-11 19:26

import uuid
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('chat', '0009_individualpipelinerecord_user_week_number'),
    ]

    operations = [
        migrations.CreateModel(
            name='GroupPipelineRecord',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('run_id', models.UUIDField(default=uuid.uuid4, editable=False, unique=True)),
                ('group_id', models.CharField(max_length=255)),
                ('ingested', models.BooleanField(default=False)),
                ('processed', models.BooleanField(default=False)),
                ('sent', models.BooleanField(default=False)),
                ('failed', models.BooleanField(default=False)),
                ('error_log', models.TextField(blank=True, null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
            ],
        ),
        migrations.AddField(
            model_name='group',
            name='initial_message',
            field=models.TextField(default=''),
        ),
        migrations.AddField(
            model_name='group',
            name='week_number',
            field=models.IntegerField(blank=True, null=True),
        ),
    ]


# File: migrations/__init__.py


# File: models.py
import uuid
from django.db import models

from .constant import MODERATION_MESSAGE_DEFAULT


class User(models.Model):
    id = models.CharField(primary_key=True, max_length=255)
    created_at = models.DateTimeField(auto_now_add=True)
    school_name = models.CharField(max_length=255, default='')
    school_mascot = models.CharField(max_length=255, default='')
    name = models.CharField(max_length=255, default='')
    initial_message = models.TextField(default='')
    is_test = models.BooleanField(default=False)
    week_number = models.IntegerField(null=True, blank=True)


class Group(models.Model):
    id = models.CharField(primary_key=True, max_length=255)
    users = models.ManyToManyField(User, related_name="groups")
    created_at = models.DateTimeField(auto_now_add=True)
    is_test = models.BooleanField(default=False)
    week_number = models.IntegerField(null=True, blank=True)
    initial_message = models.TextField(default='')


class ChatTranscript(models.Model):
    ROLE_CHOICES = (
        ('user', 'User'),
        ('assistant', 'Assistant'),
    )
    user = models.ForeignKey(
        User, on_delete=models.DO_NOTHING, related_name='transcripts')
    role = models.CharField(max_length=255, choices=ROLE_CHOICES)
    content = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)


class GroupChatTranscript(models.Model):
    ROLE_CHOICES = (
        ('user', 'User'),
        ('assistant', 'Assistant'),
    )
    group = models.ForeignKey(
        Group, on_delete=models.DO_NOTHING, related_name='transcripts')
    sender = models.ForeignKey(
        User, on_delete=models.DO_NOTHING, related_name='group_transcripts', null=True)
    role = models.CharField(max_length=255, choices=ROLE_CHOICES)
    content = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)


class Prompt(models.Model):
    week = models.IntegerField()
    activity = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)


class Control(models.Model):
    persona = models.TextField()
    system = models.TextField()
    default = models.TextField()
    moderation = models.TextField(default=MODERATION_MESSAGE_DEFAULT)
    created_at = models.DateTimeField(auto_now_add=True)


class Summary(models.Model):
    TYPE_CHOICES = [
        ('influencer', 'Influencer'),
        ('song', 'Song'),
        ('spot', 'Spot'),
        ('idea', 'Idea'),
        ('pick', 'Pick'),
    ]

    school = models.CharField(max_length=255)
    type = models.CharField(max_length=20, choices=TYPE_CHOICES)
    summary = models.TextField()
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)


class StrategyPrompt(models.Model):
    name = models.CharField(max_length=255)
    what_prompt = models.TextField(
        help_text="Prompt used to generate a response", default="")
    when_prompt = models.TextField(
        help_text="Conditions or triggers for using this strategy", default="")
    who_prompt = models.TextField(
        help_text="Criteria for selecting the response's addressee", default="")
    is_active = models.BooleanField(default=True, help_text="Soft delete flag")
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)


class IndividualPipelineRecord(models.Model):
    run_id = models.UUIDField(default=uuid.uuid4, unique=True, editable=False)
    participant_id = models.CharField(max_length=255)
    ingested = models.BooleanField(default=False)
    processed = models.BooleanField(default=False)
    sent = models.BooleanField(default=False)
    failed = models.BooleanField(default=False)
    error_log = models.TextField(blank=True, null=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    def __str__(self):
        return f"IndividualPipelineRecord({self.participant_id}, {self.run_id})"


class GroupPipelineRecord(models.Model):
    run_id = models.UUIDField(default=uuid.uuid4, unique=True, editable=False)
    group_id = models.CharField(max_length=255)
    ingested = models.BooleanField(default=False)
    processed = models.BooleanField(default=False)
    sent = models.BooleanField(default=False)
    failed = models.BooleanField(default=False)
    error_log = models.TextField(blank=True, null=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    def __str__(self):
        return f"GroupPipelineRecord({self.group_id}, {self.run_id})"


# File: moderation.py
from openai import OpenAI
from openai._compat import model_dump
client = OpenAI()

MODERATION_VALUES_FOR_BLOCKED = {
    "harassment": 0.5,
    "harassment/threatening": 0.1,
    "hate": 0.5,
    "hate/threatening": 0.1,
    "self-harm": 0.2,
    "self-harm/instructions": 0.5,
    "self-harm/intent": 0.7,
    "sexual": 0.5,
    "sexual/minors": 0.2,
    "violence": 0.7,
    "violence/graphic": 0.8,
}


def moderate_message(message: str) -> str:
    moderation_response = client.moderations.create(
        input=message, model="omni-moderation-latest"
    )
    category_scores = moderation_response.results[0].category_scores or {}

    category_score_items = model_dump(category_scores)

    blocked_str = ""
    for category, score in category_score_items.items():
        if score is None:
            continue
        if score > MODERATION_VALUES_FOR_BLOCKED.get(category, 1.0):
            blocked_str += f"({category}: {score})"
            break
    return blocked_str


# File: send.py
import httpx
import os

BCFG_DOMAIN = os.getenv("BCFG_DOMAIN", "https://bcfg-domain.com")


async def send_message_to_participant(participant_id: str, message: str):
    """
    Sends a message to a single participant via the BCFG endpoint.

    Endpoint:
      POST /ai/api/participant/{id}/send
    Body:
      { "message": "What a lovely day" }
    """
    url = f"{BCFG_DOMAIN}/ai/api/participant/{participant_id}/send"
    payload = {"message": message}
    headers = {
        "Authorization": "Bearer JLGasdfJH8lkdasop93q4lkjsedf56012879lksdfhgsd" # TODO: sync with bcfg on managing authentication tokens
    }
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload, headers=headers)
            response.raise_for_status()
            return response.json()
    except httpx.HTTPStatusError as exc:
        # Log the HTTP error details and return a default value
        print(
            f"HTTP error sending message to participant {participant_id}: {exc.response.status_code} - {exc.response.text}")
        return {"error": "HTTPStatusError", "details": str(exc)}
    except httpx.RequestError as exc:
        # Log connection related errors
        print(
            f"Request error sending message to participant {participant_id}: {exc}")
        return {"error": "RequestError", "details": str(exc)}


async def send_message_to_participant_group(group_id: str, message: str):
    """
    Sends a message to a participant group via the BCFG endpoint.

    Endpoint:
      POST /ai/api/participantgroup/{id}/send
    Body:
      { "message": "What a lovely day" }
    """
    url = f"{BCFG_DOMAIN}/ai/api/participantgroup/{group_id}/send"
    payload = {"message": message}
    headers = {
        "Authorization": "Bearer JLGasdfJH8lkdasop93q4lkjsedf56012879lksdfhgsd"
    }
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(url, json=payload, headers=headers)
            response.raise_for_status()
            return response.json()
    except httpx.HTTPStatusError as exc:
        # Log the HTTP error details and return a default value
        print(
            f"HTTP error sending message to participant group {group_id}: {exc.response.status_code} - {exc.response.text}")
        return {"error": "HTTPStatusError", "details": str(exc)}
    except httpx.RequestError as exc:
        # Log connection related errors
        print(
            f"Request error sending message to participant group {group_id}: {exc}")
        return {"error": "RequestError", "details": str(exc)}


# File: serializers.py
from rest_framework import serializers


class ContextSerializer(serializers.Serializer):
    school_name = serializers.CharField()
    school_mascot = serializers.CharField()
    initial_message = serializers.CharField()
    week_number = serializers.IntegerField()
    name = serializers.CharField()


class IncomingMessageSerializer(serializers.Serializer):
    context = ContextSerializer()
    message = serializers.CharField()


class ParticipantSerializer(serializers.Serializer):
    name = serializers.CharField()
    id = serializers.CharField()


class GroupContextSerializer(serializers.Serializer):
    school_name = serializers.CharField()
    school_mascot = serializers.CharField()
    initial_message = serializers.CharField()
    week_number = serializers.IntegerField()
    participants = ParticipantSerializer(many=True)


class GroupIncomingMessageSerializer(serializers.Serializer):
    context = GroupContextSerializer()
    sender_id = serializers.CharField()
    message = serializers.CharField()


# File: tasks.py
from celery import shared_task
from config.celery import app
import logging
from celery import shared_task


logger = logging.getLogger(__name__)


@shared_task
def add(x, y):
    return x + y


@app.task
def sample_task():
    print("Celery beat: Running sample task!")
    logger.info("Celery beat: Running sample task!")


# File: templates/chat/prompt_confirm_delete.html
{% load static %}
<!DOCTYPE html>
<html>
<head>
    <title>Delete Prompt</title>
</head>
<body>
    <h2>Delete Prompt for Week {{ prompt.week }}</h2>
    <p>Activity: {{ prompt.activity }}</p>
    <p>Are you sure you want to delete this prompt?</p>
    <form method="post">
        {% csrf_token %}
        <button type="submit">Confirm Delete</button>
        <a href="{% url 'chat:prompt_interface' %}">Cancel</a>
    </form>
</body>
</html>


# File: templates/chat/prompt_edit.html
{% load static %}
<!DOCTYPE html>
<html>
<head>
    <title>Edit Prompt</title>
</head>
<body>
    <h2>Edit Prompt for Week {{ prompt.week }}</h2>
    <form method="post">
        {% csrf_token %}
        {{ form.as_p }}
        <button type="submit">Save Changes</button>
    </form>
    <a href="{% url 'chat:prompt_interface' %}">Back to Interface</a>
</body>
</html>


# File: templates/chat/prompt_interface.html
{% load static %}
<!DOCTYPE html>
<html>
<head>
    <title>Chat Prompt Interface</title>
    <style>
        .container { display: flex; }
        .left-panel { width: 50%; padding: 10px; border-right: 1px solid #ccc; }
        .right-panel { width: 50%; padding: 10px; }
        .prompt-item { border: 1px solid #ccc; padding: 5px; margin-bottom: 5px; }
        .prompt-actions { display: inline-block; margin-left: 10px; }
    </style>
</head>
<body>
    <div class="container">
        <!-- Left Panel: Activity Prompts -->
        <div class="left-panel">
            <h2>Activity Prompts</h2>
            <form method="post">
                {% csrf_token %}
                {{ prompt_form.as_p }}
                <button type="submit" name="prompt_submit">Add Prompt</button>
            </form>
            <hr/>
            <h3>Existing Prompts</h3>
            {% if prompts %}
                <ul>
                    {% for prompt in prompts %}
                        <li class="prompt-item">
                            <strong>Week {{ prompt.week }}:</strong> {{ prompt.activity }}
                            <span class="prompt-actions">
                                <!-- Edit link -->
                                <a href="{% url 'chat:prompt_edit' prompt.id %}">Edit</a>
                                <!-- Delete button: directs to a confirmation page -->
                                <a href="{% url 'chat:prompt_delete' prompt.id %}">Delete</a>
                            </span>
                        </li>
                    {% endfor %}
                </ul>
            {% else %}
                <p>No prompts available.</p>
            {% endif %}
        </div>
        <!-- Right Panel: Control Prompt -->
        <div class="right-panel">
            <h2>Control Prompt</h2>
            <form method="post">
                {% csrf_token %}
                {{ control_form.as_p }}
                <button type="submit" name="control_submit">Update Control</button>
            </form>
        </div>
    </div>
</body>
</html>


# File: templates/chat/strategy_form.html
{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>{{ action }} Strategy Prompt</title>
</head>
<body>
    <h1>{{ action }} Strategy Prompt</h1>
    <form method="post">
        {% csrf_token %}
        {{ form.as_p }}
        <button type="submit">{{ action }}</button>
    </form>
    <a href="{% url 'chat:strategy_list' %}">Back to list</a>
</body>
</html>


# File: templates/chat/strategy_list.html
{% load static %}
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Strategy Prompts List</title>
</head>
<body>
    <h1>Strategy Prompts</h1>
    <a href="{% url 'chat:strategy_create' %}">Create New Strategy</a>
    <ul>
        {% for strategy in strategies %}
            <li>
                <strong>{{ strategy.name }}</strong>
                <a href="{% url 'chat:strategy_edit' strategy.pk %}">Edit</a>
                <a href="{% url 'chat:strategy_delete' strategy.pk %}">Delete</a>
            </li>
        {% empty %}
            <li>No strategies available.</li>
        {% endfor %}
    </ul>
</body>
</html>


# File: templates/chat/summary_form.html
{% load static %}
<!DOCTYPE html>
<html>
<head>
    <title>{% if object %}Edit{% else %}Create{% endif %} Summary</title>
</head>
<body>
    <h1>{% if object %}Edit{% else %}Create{% endif %} Summary</h1>
    <form method="post">
        {% csrf_token %}
        {{ form.as_p }}
        <button type="submit">Submit</button>
    </form>
    <a href="{% url 'chat:summary_list' %}">Back to list</a>
</body>
</html>


# File: templates/chat/summary_list.html
{% load static %}
<!DOCTYPE html>
<html>
<head>
    <title>Summary List</title>
</head>
<body>
    <h1>Summary List</h1>
    <a href="{% url 'chat:summary_create' %}">Create New Summary</a>
    <ul>
        {% for summary in summaries %}
            <li>
                {{ summary.school }} - {{ summary.type }} -
                <a href="{% url 'chat:summary_update' summary.pk %}">Edit</a>
            </li>
        {% empty %}
            <li>No summaries found.</li>
        {% endfor %}
    </ul>
</body>
</html>


# File: tests.py
from django.test import TestCase

# Create your tests here.


# File: urls.py
from .views import strategy_list, strategy_create, strategy_edit, strategy_delete
from .views import SummaryListView, SummaryCreateView, SummaryUpdateView
from django.urls import path
from .views import HealthCheckView, IngestIndividualView, IngestGroupView, PromptInterface, prompt_edit, prompt_delete, summary_view

app_name = "chat"

urlpatterns = [
    path('health/', HealthCheckView.as_view(), name='health-check'),
    path('participant/<str:id>/incoming',
         IngestIndividualView.as_view(), name='ingest-individual'),
    path('participantgroup/<str:id>/incoming',
         IngestGroupView.as_view(), name='ingest-group'),
    path('prompt/', PromptInterface.as_view(), name='prompt_interface'),
    path('prompt/edit/<int:prompt_id>/', prompt_edit, name='prompt_edit'),
    path('prompt/delete/<int:prompt_id>/', prompt_delete, name='prompt_delete'),
    path('summary', summary_view, name='summary'),
    path('summary/interface/', SummaryListView.as_view(), name='summary_list'),
    path('summary/create/', SummaryCreateView.as_view(), name='summary_create'),
    path('summary/<int:pk>/edit/',
         SummaryUpdateView.as_view(), name='summary_update'),
    path("strategies/", strategy_list, name="strategy_list"),
    path("strategies/create/", strategy_create, name="strategy_create"),
    path("strategies/<int:pk>/edit/", strategy_edit, name="strategy_edit"),
    path("strategies/<int:pk>/delete/", strategy_delete, name="strategy_delete"),
]


# File: views.py
from django.urls import reverse_lazy
from django.views.generic import ListView, CreateView, UpdateView
from django.http import JsonResponse
from django.views import View
from django import forms

from .group_pipeline import group_pipeline_ingest_task
from .individual_pipeline import individual_pipeline_ingest_task
from .models import Prompt, Control, StrategyPrompt, Summary
from django.shortcuts import render, redirect, get_object_or_404
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from .serializers import IncomingMessageSerializer, GroupIncomingMessageSerializer


class HealthCheckView(APIView):
    def get(self, request):
        return Response({"message": "Service is healthy", "status": "ok", "code": 200}, status=status.HTTP_200_OK)


class IngestIndividualView(APIView):
    def post(self, request, id):
        serializer = IncomingMessageSerializer(data=request.data)
        if serializer.is_valid():
            individual_pipeline_ingest_task.delay(
                id, serializer.validated_data)
            return Response({"message": "Data received"}, status=status.HTTP_202_ACCEPTED)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class IngestGroupView(APIView):
    def post(self, request, id):
        serializer = GroupIncomingMessageSerializer(data=request.data)
        if serializer.is_valid():
            # ingest_group_task.delay(id, serializer.validated_data)
            group_pipeline_ingest_task.delay(id, serializer.validated_data)
            return Response({"message": "Data received"}, status=status.HTTP_202_ACCEPTED)
        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)


class PromptForm(forms.ModelForm):
    class Meta:
        model = Prompt
        fields = ['week', 'activity']


class ControlForm(forms.ModelForm):
    class Meta:
        model = Control
        fields = ['persona', 'system', 'default', 'moderation']


class PromptInterface(View):
    def get(self, request):
        prompts = Prompt.objects.all().order_by('-created_at')
        control_instance = Control.objects.last()
        if not control_instance:
            control_instance = Control.objects.create(
                persona='', system='', default='')
        prompt_form = PromptForm()
        control_form = ControlForm(instance=control_instance)
        context = {
            'prompts': prompts,
            'prompt_form': prompt_form,
            'control_form': control_form,
        }
        return render(request, 'chat/prompt_interface.html', context)

    def post(self, request):
        prompts = Prompt.objects.all().order_by('-created_at')
        control_instance = Control.objects.last()
        if 'prompt_submit' in request.POST:
            prompt_form = PromptForm(request.POST)
            if prompt_form.is_valid():
                prompt_form.save()
                return redirect('chat:prompt_interface')
        elif 'control_submit' in request.POST:
            if control_instance:
                control_form = ControlForm(
                    request.POST, instance=control_instance)
            else:
                control_form = ControlForm(request.POST)
            if control_form.is_valid():
                control_form.save()
                return redirect('chat:prompt_interface')
        prompt_form = PromptForm()
        control_form = ControlForm(instance=control_instance)
        context = {
            'prompts': prompts,
            'prompt_form': prompt_form,
            'control_form': control_form,
        }
        return render(request, 'chat/prompt_interface.html', context)


def prompt_edit(request, prompt_id):
    """
    Provides an interface to edit an existing activity prompt.
    """
    prompt = get_object_or_404(Prompt, id=prompt_id)
    if request.method == 'POST':
        form = PromptForm(request.POST, instance=prompt)
        if form.is_valid():
            form.save()
            return redirect('chat:prompt_interface')
    else:
        form = PromptForm(instance=prompt)
    return render(request, 'chat/prompt_edit.html', {'form': form, 'prompt': prompt})


def prompt_delete(request, prompt_id):
    """
    Provides an interface to confirm and delete a prompt.
    """
    prompt = get_object_or_404(Prompt, id=prompt_id)
    if request.method == 'POST':
        prompt.delete()
        return redirect('chat:prompt_interface')
    return render(request, 'chat/prompt_confirm_delete.html', {'prompt': prompt})


SUMMARY_ALLOWED_TYPES = ['influencer', 'song', 'spot', 'idea', 'pick']


def summary_view(request):
    school = request.GET.get('school')
    type_param = request.GET.get('type')

    # Validate query parameters
    if not school:
        return JsonResponse({"error": "Missing school parameter."}, status=400)
    if not type_param:
        return JsonResponse({"error": "Missing type parameter."}, status=400)
    if type_param not in SUMMARY_ALLOWED_TYPES:
        return JsonResponse(
            {"error": f"Invalid type parameter. Allowed values: {', '.join(SUMMARY_ALLOWED_TYPES)}."},
            status=400
        )

    # Check if the school exists in any summary record
    if not Summary.objects.filter(school=school).exists():
        return JsonResponse({"error": "School not found."}, status=404)

    # Retrieve the most recently updated summary for the given school and type
    summary = Summary.objects.filter(
        school=school, type=type_param).order_by('-updated_at').first()

    if not summary:
        return JsonResponse({"error": f"No summary found for {school} with type {type_param}."}, status=404)

    data = summary.summary

    return JsonResponse({"summary": data}, status=200)


class SummaryForm(forms.ModelForm):
    class Meta:
        model = Summary
        fields = ['school', 'type', 'summary']


class SummaryListView(ListView):
    model = Summary
    template_name = 'chat/summary_list.html'
    context_object_name = 'summaries'


class SummaryCreateView(CreateView):
    model = Summary
    form_class = SummaryForm
    template_name = 'chat/summary_form.html'
    success_url = reverse_lazy('chat:summary_list')


class SummaryUpdateView(UpdateView):
    model = Summary
    form_class = SummaryForm
    template_name = 'chat/summary_form.html'
    success_url = reverse_lazy('chat:summary_list')


class StrategyPromptForm(forms.ModelForm):
    class Meta:
        model = StrategyPrompt
        fields = ['name', 'what_prompt',
                  'when_prompt', 'who_prompt', 'is_active']


def strategy_list(request):
    """List all active strategy prompts."""
    strategies = StrategyPrompt.objects.filter(is_active=True)
    return render(request, "chat/strategy_list.html", {"strategies": strategies})


def strategy_create(request):
    """Create a new strategy prompt."""
    if request.method == "POST":
        form = StrategyPromptForm(request.POST)
        if form.is_valid():
            form.save()
            return redirect("chat:strategy_list")
    else:
        form = StrategyPromptForm()
    return render(request, "chat/strategy_form.html", {"form": form, "action": "Create"})


def strategy_edit(request, pk):
    """Edit an existing strategy prompt."""
    strategy = get_object_or_404(StrategyPrompt, pk=pk)
    if request.method == "POST":
        form = StrategyPromptForm(request.POST, instance=strategy)
        if form.is_valid():
            form.save()
            return redirect("chat:strategy_list")
    else:
        form = StrategyPromptForm(instance=strategy)
    return render(request, "chat/strategy_form.html", {"form": form, "action": "Edit"})


def strategy_delete(request, pk):
    """Soft delete a strategy prompt by marking it inactive."""
    strategy = get_object_or_404(StrategyPrompt, pk=pk)
    # Soft delete: mark as inactive
    strategy.is_active = False
    strategy.save()
    return redirect("chat:strategy_list")


